import streamlit as st
import pandas as pd
import mysql.connector
from config import MYSQL_CONFIG
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
import networkx as nx
from collections import Counter
from itertools import combinations
from io import BytesIO
import matplotlib.font_manager as fm
import plotly.graph_objects as go
from datetime import datetime, timedelta
import platform
import os


# ------------------------
# OSë³„ í°íŠ¸ ê²½ë¡œ ìë™ ì„¤ì •
# ------------------------
def get_font_path():
    system = platform.system()
    if system == "Windows":
        return "C:/Windows/Fonts/malgun.ttf"
    elif system == "Darwin":  # macOS
        mac_fonts = [
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/Library/Fonts/AppleGothic.ttf",
            "/Library/Fonts/NanumGothic.ttf"
        ]
        for path in mac_fonts:
            if os.path.exists(path):
                return path
        raise FileNotFoundError("macOSì—ì„œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    elif system == "Linux":
        linux_fonts = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
        ]
        for path in linux_fonts:
            if os.path.exists(path):
                return path
        raise FileNotFoundError("Linuxì—ì„œ ê¸°ë³¸ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        raise OSError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œì…ë‹ˆë‹¤.")

FONT_PATH = get_font_path()

# Stopwords ì •ì˜
STOPWORDS = set([
    'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë”', 'ìœ„í•´', 'ë˜í•œ', 'ìˆëŠ”', 'í•˜ëŠ”', 'ì—ì„œ', 'ìœ¼ë¡œ',
    'ê·¸ë¦¬ê³ ', 'ì´ë²ˆ', 'í•œí¸', 'ìˆë‹¤', 'í–ˆë‹¤', 'ëŒ€í•œ', 'ê°€ì¥', 'ì´ëŸ°',
    'í•œë‹¤', 'í•œë‹¤ë©´', 'ë°”', 'ë•Œ', 'ë‹¤ì–‘í•œ', 'í†µí•´', 'ê¸°ì', 'ìµœê·¼',
    'ìš°ë¦¬', 'ë§ì€', 'ì¤‘', 'ë•Œë¬¸', 'ëŒ€í•œ', 'ëª¨ë“ ', 'í•˜ì§€ë§Œ', 'ì¤‘ì¸',
    'ì´í›„', 'ê·¸ë…€', 'ê·¸ëŠ”', 'ì—ì„œì˜', 'ìˆëŠ”ì§€', 'ì¤‘ì‹¬', 'ëœë‹¤', 'ìˆìœ¼ë©°',
    'ëœë‹¤', 'ëœë‹¤ë©´', 'ìœ„í•œ','ìŠ¤íƒ€ì¼ë§', 'ìŠ¤íƒ€ì¼', 'ì•„ì´í…œ', 'íŒ¨ì…˜', 'ë¸Œëœë“œ',
    'ì»¬ë ‰ì…˜', 'ì½”ë””', 'ì»¬ëŸ¬', 'íŠ¸ë Œë“œ', 'ë””ìì´ë„ˆ', 'ì‡¼í•‘', 'ì½”ë””', 'ì½”ë””ë„¤ì´í„°', 'ì½”ë””ë²•', 'ì½”ë””ì¶”ì²œ', 'ì½”ë””ì•„ì´í…œ', 'ë°•ì†Œí˜„', 'í™©ê¸°ì• ', 'ì •í˜œë¯¸', 'ì§„ì •',
    'ë¬´ë“œ', 'ëŠë‚Œ', 'ë¶„ìœ„ê¸°', 'ë§¤ë ¥', 'í™œìš©', 'ì™„ì„±', 'ì—°ì¶œ', 'ì„ íƒ', 'ì¡°í•©', 'í¬ì¸íŠ¸', 'ë‹¤ì–‘', 'ëª¨ìŠµ', 'ìì‹ ', 'ì‚¬ëŒ', 'ë§ˆìŒ',
    'ì œí’ˆ', 'ë””ìì¸', 'ì—ë””í„°', 'ì •ìœ¤', 'ë³´ê·¸', 'ë…„ëŒ€', 'ë“±ì¥' 'ì‹œì¦Œ', 'ìŠ¤íƒ€ì¼ë§', 'ìŠ¤íƒ€ì¼', 'ì•„ì´í…œ', 'íŒ¨ì…˜', 'ë¸Œëœë“œ', 'ì¥ì§„ì˜', 'ìœ¤ë‹¤í¬', 'ê°•ë¯¸', 'ë°•ì€ì•„', 
])

def remove_stopwords(tokens):
    return [t for t in tokens if t not in STOPWORDS and len(t) > 1]

# ------------------------
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# ------------------------
def get_mysql_connection():
    return mysql.connector.connect(**MYSQL_CONFIG)

@st.cache_data
def load_data():
    conn = get_mysql_connection()
    query = "SELECT doc_domain, upload_date, tokens, source FROM magazine_tokenised;"
    df = pd.read_sql(query, conn)
    conn.close()
    df['tokens'] = df['tokens'].apply(eval)
    df['upload_date'] = pd.to_datetime(df['upload_date'])
    return df

df = load_data()

# ------------------------
# ì‚¬ì´ë“œë°” í•„í„°
# ------------------------
st.sidebar.title("í•„í„°")
category = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬", df['doc_domain'].unique())
filtered_df = df[df['doc_domain'] == category]

# ------------------------
# íƒ­ êµ¬ì„±
# ------------------------
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š í‚¤ì›Œë“œ íŠ¸ë Œë“œ", "ğŸ“ˆ TF-IDF ë¶„ì„", "ğŸ•¸ï¸ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬", "ğŸ“‰ ì•„ì´í…œ ì¦ê°ë¥  ë¶„ì„", "ğŸ“° ë§¤ê±°ì§„ë³„ ë¶„ì„"
])


# ------------------------
# ğŸ“Š íƒ­ 1: íŠ¸ë Œë“œ
# ------------------------
with tab1:
    st.subheader(f"{category.upper()} ìƒìœ„ í‚¤ì›Œë“œ Top 20")
    all_tokens = [token for tokens in filtered_df['tokens'] for token in remove_stopwords(tokens)]
    token_counts = pd.Series(all_tokens).value_counts().head(20).reset_index()
    token_counts.columns = ['token', 'count']
    fig = px.bar(token_counts, x='token', y='count')
    st.plotly_chart(fig)

    st.subheader("ì›Œë“œí´ë¼ìš°ë“œ")
    wordcloud = WordCloud(
        font_path=FONT_PATH,
        background_color="white",
        width=800,
        height=400
    ).generate(' '.join(all_tokens))
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

# ------------------------
# ğŸ“ˆ íƒ­ 2: TF-IDF
# ------------------------
with tab2:
    st.subheader("TF-IDF í•µì‹¬ í‚¤ì›Œë“œ")
    filtered_df = filtered_df.reset_index(drop=True)
    article_idx = st.selectbox("ê¸°ì‚¬ ì„ íƒ (ì¸ë±ìŠ¤)", range(len(filtered_df)))
    
    docs = filtered_df['tokens'].apply(lambda x: ' '.join(remove_stopwords(x))).tolist()
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(docs)
    feature_names = vectorizer.get_feature_names_out()
    scores = tfidf_matrix[article_idx].toarray()[0]
    top_n = scores.argsort()[-20:][::-1]
    top_keywords = [(feature_names[i], scores[i]) for i in top_n if scores[i] > 0]

    if top_keywords:
        tk_df = pd.DataFrame(top_keywords, columns=['token', 'tfidf'])
        fig = px.bar(tk_df, x='token', y='tfidf')
        st.plotly_chart(fig)
    else:
        st.info("TF-IDF í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------
# ğŸ•¸ï¸ íƒ­ 3: ë„¤íŠ¸ì›Œí¬
# ------------------------
with tab3:
    st.subheader("í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”")

    font_path = FONT_PATH
    font_prop = fm.FontProperties(fname=font_path)
    font_name = font_prop.get_name()

    edge_counter = Counter()
    for tokens in filtered_df['tokens']:
        cleaned = remove_stopwords(tokens)
        unique_tokens = list(set(cleaned))
        if len(unique_tokens) >= 2:
            edge_counter.update(combinations(unique_tokens, 2))
    top_edges = edge_counter.most_common(30)

    G = nx.Graph()
    G.add_edges_from([(a, b, {'weight': w}) for (a, b), w in top_edges])

    pos = nx.spring_layout(G, k=0.5, seed=42)
    weights = [G[u][v]['weight'] for u, v in G.edges()]
    plt.figure(figsize=(10, 8))
    nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=600)
    nx.draw_networkx_edges(G, pos, edge_color=weights, edge_cmap=plt.cm.Blues, width=2)
    nx.draw_networkx_labels(G, pos, font_family=font_name, font_size=10)
    st.pyplot(plt.gcf())


# ------------------------
# ğŸ“‰ íƒ­ 4: ì•„ì´í…œ ì¦ê°ë¥  ë¶„ì„
# ------------------------
with tab4:
    st.subheader("ğŸ§¥ ì•„ì´í…œ íŠ¸ë Œë“œ ë³€í™” (ê¸°ê°„ë³„ ë¹„êµ)")

    # ê¸°ì¤€ ì„ íƒ
    keyword_type = st.radio("ê¸°ì¤€:", ["ì•„ì´í…œ", "ì»¬ëŸ¬", "ì†Œì¬", "í”„ë¦°íŠ¸", "ìŠ¤íƒ€ì¼"], horizontal=True)

    # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (ë™ì˜ì–´/ìœ ì‚¬ì–´ ë¬¶ê¸°)
    keyword_dict = {
        "ì•„ì´í…œ": ['ë“œë ˆìŠ¤', 'ì¬í‚·', 'íŒ¬ì¸ ', 'ìŠ¤ì»¤íŠ¸', 'ì½”íŠ¸', 'ë¸”ë¼ìš°ìŠ¤', 'ìºì£¼ì–¼ìƒì˜', 'ì í”„ìˆ˜íŠ¸', 'ë‹ˆíŠ¸ì›¨ì–´', 'ì…”ì¸ ', 'íƒ‘', 'ì²­ë°”ì§€', 'ìˆ˜ì˜ë³µ', 'ì í¼', 'ë² ìŠ¤íŠ¸', 'íŒ¨ë”©'],
        "ì»¬ëŸ¬": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ë² ì´ì§€', 'ë¸Œë¼ìš´', 'ê·¸ë ˆì´', 'ë¸”ë£¨', 'ìŠ¤ì¹´ì´ë¸”ë£¨', 'ë„¤ì´ë¹„', 'ì˜ë¡œìš°', 'í•‘í¬', 'ë ˆë“œ', 'ì¹´í‚¤', 'ë¼ë²¤ë”', 'ê·¸ë¦°', 'í¼í”Œ', 'ë¯¼íŠ¸', 'ì˜¤ë Œì§€', 'ì™€ì¸', 'ë©€í‹°'],
        "ì†Œì¬": ['í•©ì„±ì„¬ìœ ', 'ë©´', 'ê°€ì£½', 'ì‹œí°', 'ë‹ˆíŠ¸', 'ë°ë‹˜', 'ë ˆì´ìŠ¤', 'ì‹œí€¸/ê¸€ë¦¬í„°', 'ìºì‹œë¯¸ì–´/ìš¸', 'ìŠ¤ì›¨ì´ë“œ', 'ë²¨ë²³', 'ìŠ¤íŒë±ìŠ¤', 'í¼', 'íŠ¸ìœ„ë“œ', 'ë¹„ë‹/PVC', 'ë©”ì‹œ', 'ë¦°ë„¨', 'ìì¹´ë“œ', 'ì €ì§€', 'ì½”ë“€ë¡œì´', 'ë„¤ì˜¤í”„ë Œ', 'í”Œë¦¬ìŠ¤', 'ë¬´ìŠ¤íƒ•', 'ì•™ê³ ë¼', 'ì‹¤í¬'],
        "í”„ë¦°íŠ¸": ['ë¬´ì§€', 'í”Œë¡œëŸ´', 'ìŠ¤íŠ¸ë¼ì´í”„', 'ì²´í¬', 'ê·¸ë˜í”½', 'ë„íŠ¸', 'ë ˆí„°ë§', 'í˜ì´ì¦ë¦¬', 'í˜¸í”¼', 'ê·¸ë¼ë°ì´ì…˜', 'íƒ€ì´ë‹¤ì´', 'ì¹´ë¬´í”Œë¼ì¥¬/ì¹´ëª¨í”Œë¼ì¥¬', 'ì§€ê·¸ì¬ê·¸', 'ì§€ë¸Œë¼', 'í•´ê³¨', 'ë©€í‹°'],
        "ìŠ¤íƒ€ì¼": ['ì»¨íŠ¸ë¦¬', 'ì›¨ë”©', 'í”„ë ˆí”¼', 'íˆí”¼', 'ì•„ì›ƒë„ì–´', 'ë°€ë¦¬í„°ë¦¬', 'ë³µê³ ', 'í˜ë¯¸ë‹Œ', 'ìºì£¼ì–¼', 'ë§ˆë¦°', 'ì—ìŠ¤ë‹‰', 'ì˜¤í”¼ìŠ¤ë£©', 'íŒŒí‹°', 'ë¦¬ì¡°íŠ¸', 'í‘í¬']
    }

    keyword_aliases = {
        'ì‹œí€¸/ê¸€ë¦¬í„°': ['ì‹œí€¸', 'ê¸€ë¦¬í„°'],
        'ìºì‹œë¯¸ì–´/ìš¸': ['ìºì‹œë¯¸ì–´', 'ìš¸'],
        'ë¹„ë‹/PVC': ['ë¹„ë‹', 'pvc', 'PVC'],
        'ì¹´ë¬´í”Œë¼ì¥¬/ì¹´ëª¨í”Œë¼ì¥¬': ['ì¹´ë¬´í”Œë¼ì¥¬', 'ì¹´ëª¨í”Œë¼ì¥¬']
    }

    ITEM_KEYWORDS = keyword_dict[keyword_type]

    st.markdown("### ğŸ“† ë¶„ì„ ê¸°ê°„ ì„¤ì •")
    period_option = st.selectbox("ë¹„êµ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”", ['1ì£¼ì¼', '2ì£¼ì¼', '1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„', '2ë…„', 'ì§ì ‘ ì„¤ì •'])

    today = pd.to_datetime(datetime.today().date())
    if period_option == 'ì§ì ‘ ì„¤ì •':
        col1, col2 = st.columns(2)
        with col1:
            curr_start = st.date_input("í˜„ì¬ ì‹œì‘ì¼", value=today - timedelta(days=30))
            curr_end = st.date_input("í˜„ì¬ ì¢…ë£Œì¼", value=today)
        with col2:
            prev_start = st.date_input("ì´ì „ ì‹œì‘ì¼", value=today - timedelta(days=60))
            prev_end = st.date_input("ì´ì „ ì¢…ë£Œì¼", value=today - timedelta(days=31))
    else:
        delta_map = {
            '1ì£¼ì¼': 7,
            '2ì£¼ì¼': 14,
            '1ê°œì›”': 30,
            '3ê°œì›”': 90,
            '6ê°œì›”': 180,
            '1ë…„': 365,
            '2ë…„': 730
        }
        delta = timedelta(days=delta_map[period_option])
        curr_end = today
        curr_start = today - delta
        prev_end = curr_start - timedelta(days=1)
        prev_start = prev_end - delta + timedelta(days=1)

    # ê¸°ê°„ë³„ ë°ì´í„° í•„í„°ë§
    df_before = filtered_df[
        (filtered_df['upload_date'] >= pd.to_datetime(prev_start)) &
        (filtered_df['upload_date'] <= pd.to_datetime(prev_end))
    ]
    df_current = filtered_df[
        (filtered_df['upload_date'] >= pd.to_datetime(curr_start)) &
        (filtered_df['upload_date'] <= pd.to_datetime(curr_end))
    ]

    def count_items(df):
        all_tokens = [token for tokens in df['tokens'] for token in remove_stopwords(tokens)]
        counts = pd.Series(all_tokens).value_counts()
        result = {}
        for item in ITEM_KEYWORDS:
            if item in keyword_aliases:
                result[item] = sum(counts.get(alias, 0) for alias in keyword_aliases[item])
            else:
                result[item] = counts.get(item, 0)
        return result

    counts_current = count_items(df_current)
    counts_before = count_items(df_before)

    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    trend_df = pd.DataFrame({
        'item': ITEM_KEYWORDS,
        'í˜„ì¬ ì–¸ê¸‰ëŸ‰': [counts_current[i] for i in ITEM_KEYWORDS],
        'ì´ì „ ì–¸ê¸‰ëŸ‰': [counts_before[i] for i in ITEM_KEYWORDS]
    })
    trend_df['ì¦ê°ë¥ (%)'] = ((trend_df['í˜„ì¬ ì–¸ê¸‰ëŸ‰'] - trend_df['ì´ì „ ì–¸ê¸‰ëŸ‰']) /
                         trend_df['ì´ì „ ì–¸ê¸‰ëŸ‰'].replace(0, 1)) * 100

    # ì‹œê°í™” â‘  ì´ì „ vs í˜„ì¬ ì–¸ê¸‰ëŸ‰
    st.markdown("### ğŸ“Š ì´ì „ vs í˜„ì¬ ì–¸ê¸‰ëŸ‰ ë¹„êµ")
    fig_compare = px.bar(
        trend_df.melt(id_vars='item', value_vars=['ì´ì „ ì–¸ê¸‰ëŸ‰', 'í˜„ì¬ ì–¸ê¸‰ëŸ‰'], 
                      var_name='ê¸°ê°„', value_name='ì–¸ê¸‰ëŸ‰')
        .replace({
            'ì´ì „ ì–¸ê¸‰ëŸ‰': f"{prev_start.strftime('%Y.%m.%d')}~{prev_end.strftime('%Y.%m.%d')}",
            'í˜„ì¬ ì–¸ê¸‰ëŸ‰': f"{curr_start.strftime('%Y.%m.%d')}~{curr_end.strftime('%Y.%m.%d')}"
        }),
        x='item', y='ì–¸ê¸‰ëŸ‰', color='ê¸°ê°„',
        barmode='group', title=f"{keyword_type}ë³„ ì–¸ê¸‰ëŸ‰ (ì´ì „ vs í˜„ì¬)",
        labels={'item': keyword_type}
    )
    st.plotly_chart(fig_compare)

    # ì‹œê°í™” â‘¡ ì¦ê°ë¥ 
    st.markdown("### ğŸ“ˆ ì¦ê°ë¥ (%) ë³€í™”")
    fig_pct = px.bar(
        trend_df.sort_values("ì¦ê°ë¥ (%)", ascending=False),
        x="item", y="ì¦ê°ë¥ (%)", title=f"{keyword_type}ë³„ ì¦ê°ë¥ (%) ë³€í™”",
        labels={"item": keyword_type}
    )
    st.plotly_chart(fig_pct)


    # ì‹œê°í™” â‘¢ ë¼ì¸ê·¸ë˜í”„: ê¸°ê°„ë³„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸
    st.markdown("### ğŸ“‰ ê¸°ê°„ë³„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸ (ë¼ì¸ ê·¸ë˜í”„)")
    freq_option = st.selectbox("ê·¸ë˜í”„ ê¸°ì¤€ ê¸°ê°„ ì„ íƒ (ì¼ì ê¸°ì¤€)", ['1ì£¼ì¼', '1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„'], index=1)

    freq_days = {
        '1ì£¼ì¼': 7,
        '1ê°œì›”': 30,
        '3ê°œì›”': 90,
        '6ê°œì›”': 180,
        '1ë…„': 365
    }
    graph_delta = timedelta(days=freq_days[freq_option])
    graph_start = today - graph_delta
    df_graph = filtered_df[(filtered_df['upload_date'] >= graph_start) & (filtered_df['upload_date'] <= today)].copy()
    df_graph['upload_date'] = pd.to_datetime(df_graph['upload_date'])

    # ì§‘ê³„
    def count_weekly_mentions(df, keyword_list):
        df['week'] = df['upload_date'].dt.to_period('W').apply(lambda r: r.start_time)
        rows = []
        for week, group in df.groupby('week'):
            tokens = [token for tokens in group['tokens'] for token in remove_stopwords(tokens)]
            counts = pd.Series(tokens).value_counts()
            row = {'week': week}
            for kw in keyword_list:
                aliases = keyword_aliases.get(kw, [kw])
                row[kw] = sum(counts.get(a, 0) for a in aliases)
            rows.append(row)
        return pd.DataFrame(rows).sort_values('week')

    df_line = count_weekly_mentions(df_graph, ITEM_KEYWORDS)
    df_line_melted = df_line.melt(id_vars='week', var_name='í‚¤ì›Œë“œ', value_name='ì–¸ê¸‰ëŸ‰')

    # í‚¤ì›Œë“œ í•„í„° ì¶”ê°€
    selected_keywords = st.multiselect("í™•ì¸í•  í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ITEM_KEYWORDS, default=ITEM_KEYWORDS[:5])
    df_line_melted = df_line_melted[df_line_melted['í‚¤ì›Œë“œ'].isin(selected_keywords)]

    fig_line = px.line(
        df_line_melted,
        x='week', y='ì–¸ê¸‰ëŸ‰', color='í‚¤ì›Œë“œ',
        title=f"{keyword_type}ë³„ {freq_option}ê°„ ì£¼ê°„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸",
        labels={'week': 'ì£¼ì°¨'}
    )
    st.plotly_chart(fig_line)

    # í…Œì´ë¸” ì¶œë ¥
    st.dataframe(trend_df.sort_values("í˜„ì¬ ì–¸ê¸‰ëŸ‰", ascending=False), use_container_width=True)


# ------------------------
# ğŸ“° íƒ­ 5: ë§¤ê±°ì§„ ë¹„êµ
# ------------------------
with tab5:
    st.subheader("ğŸ“° ë§¤ê±°ì§„ë³„ íŠ¸ë Œë“œ ë¹„êµ ë¶„ì„")

    # ë§¤ê±°ì§„ ì„ íƒ
    magazines = sorted(filtered_df['source'].unique())
    selected_magazines = st.multiselect("ë§¤ê±°ì§„ ì„ íƒ", magazines, default=magazines[:3])

    # ë¶„ì„ ê¸°ê°„ ì„¤ì •
    date_range = st.selectbox("ë¶„ì„ ê¸°ê°„", ['1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„', 'ì „ì²´'] )
    today = pd.to_datetime(datetime.today().date())
    days_map = {'1ê°œì›”': 30, '3ê°œì›”': 90, '6ê°œì›”': 180, '1ë…„': 365}
    if date_range != 'ì „ì²´':
        start_date = today - timedelta(days=days_map[date_range])
        df_mag = filtered_df[(filtered_df['upload_date'] >= start_date)]
    else:
        df_mag = filtered_df.copy()

    df_mag = df_mag[df_mag['source'].isin(selected_magazines)]

    # ------------------------
    # 1ï¸âƒ£ ìƒìœ„ í‚¤ì›Œë“œ ë¹„êµ
    # ------------------------
    st.markdown("### ğŸ” ë§¤ê±°ì§„ë³„ ìƒìœ„ í‚¤ì›Œë“œ TOP 30")
    top_tokens_per_mag = {}
    for mag in selected_magazines:
        tokens = [token for tokens in df_mag[df_mag['source'] == mag]['tokens'] for token in remove_stopwords(tokens)]
        top_tokens_per_mag[mag] = pd.Series(tokens).value_counts().head(30)

    fig_top = go.Figure()
    for mag in selected_magazines:
        fig_top.add_trace(go.Bar(
            x=top_tokens_per_mag[mag].index,
            y=top_tokens_per_mag[mag].values,
            name=mag
        ))
    fig_top.update_layout(barmode='group', title="ë§¤ê±°ì§„ë³„ ìƒìœ„ í‚¤ì›Œë“œ ë¹„êµ", xaxis_title="í‚¤ì›Œë“œ", yaxis_title="ì–¸ê¸‰ëŸ‰")
    st.plotly_chart(fig_top)

    # ------------------------
    # 2ï¸âƒ£ ê³µí†µ vs ê³ ìœ  í‚¤ì›Œë“œ
    # ------------------------
    st.markdown("### ğŸ§¬ ê³µí†µ í‚¤ì›Œë“œ vs ê³ ìœ  í‚¤ì›Œë“œ")
    token_sets = {mag: set(top_tokens_per_mag[mag].index) for mag in selected_magazines}
    common_tokens = set.intersection(*token_sets.values()) if len(token_sets) > 1 else set()
    unique_tokens = {mag: token_sets[mag] - common_tokens for mag in selected_magazines}

    st.markdown("#### ğŸ§© ê³µí†µ í‚¤ì›Œë“œ")
    if common_tokens:
        tags_html = "".join([
            f"<span style='background:#E0F7FA; padding:6px 12px; border-radius:15px; margin:4px; display:inline-block;'>{kw}</span>"
            for kw in sorted(common_tokens)
        ])
        st.markdown(tags_html, unsafe_allow_html=True)
    else:
        st.markdown("-")

    st.markdown("#### âœ´ï¸ ë§¤ê±°ì§„ë³„ ê³ ìœ  í‚¤ì›Œë“œ")
    col_count = 3 if len(selected_magazines) >= 3 else len(selected_magazines)
    cols = st.columns(col_count)
    colors = ["#3CB371", "#1E90FF", "#FF6347", "#9370DB"]  # ì¹´ë“œ ìƒ‰ìƒ
    for idx, mag in enumerate(selected_magazines):
        with cols[idx % col_count]:
            st.markdown(f"""
                <div style='background-color:{colors[idx % len(colors)]}; padding: 10px 15px; border-radius: 10px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>
                    <h5 style='color:white; text-align:center; font-size:18px; margin-bottom:8px;'>{mag}</h5>
                    <ol style='color:white; font-size:15px;'>
                        {''.join(f'<li>{kw}</li>' for kw in sorted(unique_tokens[mag])[:10])}
                    </ol>
                </div>
            """, unsafe_allow_html=True)

    # ------------------------
    # 3ï¸âƒ£ TF-IDF ê³ ìœ  í‚¤ì›Œë“œ ë¶„ì„
    # ------------------------
    st.markdown("### ğŸ§  ë§¤ê±°ì§„ë³„ TF-IDF ëŒ€í‘œ í‚¤ì›Œë“œ")
    mag_groups = df_mag.groupby("source")['tokens'].apply(lambda x: [w for lst in x for w in remove_stopwords(lst)])
    docs = [" ".join(tokens) for tokens in mag_groups]
    tfidf = TfidfVectorizer()
    tfidf_matrix = tfidf.fit_transform(docs)
    feature_names = tfidf.get_feature_names_out()

    col_count = 3 if len(selected_magazines) >= 3 else len(selected_magazines)
    cols = st.columns(col_count)
    colors = ["#3CB371", "#1E90FF", "#FF6347", "#9370DB"]

    for i, mag in enumerate(mag_groups.index):
        row = tfidf_matrix[i].toarray().flatten()
        top_n = row.argsort()[-10:][::-1]
        keywords = [(feature_names[j], round(row[j], 4)) for j in top_n]
        with cols[i % col_count]:
            st.markdown(f"""
                <div style='background-color:{colors[i % len(colors)]}; padding: 10px 15px; border-radius: 10px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>
                    <h5 style='color:white; text-align:center; font-size:18px; margin-bottom:8px;'>{mag}</h5>
                    <ol style='color:white; font-size:15px;'>
                        {''.join(f'<li>{kw[0]} ({kw[1]})</li>' for kw in keywords)}
                    </ol>
                </div>
            """, unsafe_allow_html=True)

    # ------------------------
    # 4ï¸âƒ£ í‚¤ì›Œë“œë³„ ë§¤ê±°ì§„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸ (ë¼ì¸ê·¸ë˜í”„)
    # ------------------------
    st.markdown("### ğŸ“ˆ í‚¤ì›Œë“œë³„ ë§¤ê±°ì§„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸")
    focus_keywords_input = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value='ë¸”ë™, ì‹œì–´, í´ë˜ì‹')
    focus_keywords = [kw.strip() for kw in focus_keywords_input.split(',') if kw.strip()]

    df_mag['week'] = df_mag['upload_date'].dt.to_period('W').apply(lambda r: r.start_time)
    trend_rows = []

    for mag in selected_magazines:
        mag_df = df_mag[df_mag['source'] == mag]
        for week, group in mag_df.groupby('week'):
            all_tokens = [token for tokens in group['tokens'] for token in remove_stopwords(tokens)]
            token_counts = pd.Series(all_tokens).value_counts()
            for kw in focus_keywords:
                trend_rows.append({
                    'week': week,
                    'keyword': kw,
                    'count': token_counts.get(kw, 0),
                    'magazine': mag
                })

    df_kw_trend = pd.DataFrame(trend_rows)
    fig_kw_line = px.line(
        df_kw_trend,
        x='week', y='count', color='magazine',
        facet_col='keyword', facet_col_wrap=2,
        markers=True,
        title='ì„ íƒ í‚¤ì›Œë“œë³„ ë§¤ê±°ì§„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸',
        labels={'count': 'ì–¸ê¸‰ëŸ‰', 'week': 'ì£¼ì°¨', 'magazine': 'ë§¤ê±°ì§„'}
    )
    st.plotly_chart(fig_kw_line)