import streamlit as st
import pandas as pd
import mysql.connector
from config import MYSQL_CONFIG
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
import networkx as nx
from collections import Counter
from itertools import combinations
from io import BytesIO
import matplotlib.font_manager as fm
import plotly.graph_objects as go
from datetime import datetime, timedelta


# Stopwords ì •ì˜
STOPWORDS = set([
    'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë”', 'ìœ„í•´', 'ë˜í•œ', 'ìˆëŠ”', 'í•˜ëŠ”', 'ì—ì„œ', 'ìœ¼ë¡œ',
    'ê·¸ë¦¬ê³ ', 'ì´ë²ˆ', 'í•œí¸', 'ìˆë‹¤', 'í–ˆë‹¤', 'ëŒ€í•œ', 'ê°€ì¥', 'ì´ëŸ°',
    'í•œë‹¤', 'í•œë‹¤ë©´', 'ë°”', 'ë•Œ', 'ë‹¤ì–‘í•œ', 'í†µí•´', 'ê¸°ì', 'ìµœê·¼',
    'ìš°ë¦¬', 'ë§ì€', 'ì¤‘', 'ë•Œë¬¸', 'ëŒ€í•œ', 'ëª¨ë“ ', 'í•˜ì§€ë§Œ', 'ì¤‘ì¸',
    'ì´í›„', 'ê·¸ë…€', 'ê·¸ëŠ”', 'ì—ì„œì˜', 'ìˆëŠ”ì§€', 'ì¤‘ì‹¬', 'ëœë‹¤', 'ìˆìœ¼ë©°',
    'ëœë‹¤', 'ëœë‹¤ë©´', 'ìœ„í•œ','ìŠ¤íƒ€ì¼ë§', 'ìŠ¤íƒ€ì¼', 'ì•„ì´í…œ', 'íŒ¨ì…˜', 'ë¸Œëœë“œ',
    'ì»¬ë ‰ì…˜', 'ì½”ë””', 'ì»¬ëŸ¬', 'íŠ¸ë Œë“œ', 'ë””ìì´ë„ˆ', 'ì‡¼í•‘', 'ì½”ë””', 'ì½”ë””ë„¤ì´í„°', 'ì½”ë””ë²•', 'ì½”ë””ì¶”ì²œ', 'ì½”ë””ì•„ì´í…œ', 'ë°•ì†Œí˜„', 'í™©ê¸°ì• ', 'ì •í˜œë¯¸', 'ì§„ì •',
    'ë¬´ë“œ', 'ëŠë‚Œ', 'ë¶„ìœ„ê¸°', 'ë§¤ë ¥', 'í™œìš©', 'ì™„ì„±', 'ì—°ì¶œ', 'ì„ íƒ', 'ì¡°í•©', 'í¬ì¸íŠ¸', 'ë‹¤ì–‘', 'ëª¨ìŠµ', 'ìì‹ ', 'ì‚¬ëŒ', 'ë§ˆìŒ',
    'ì œí’ˆ', 'ë””ìì¸', 'ì—ë””í„°', 'ì •ìœ¤', 'ë³´ê·¸', 'ë…„ëŒ€', 'ë“±ì¥'
])

def remove_stopwords(tokens):
    return [t for t in tokens if t not in STOPWORDS and len(t) > 1]

# ------------------------
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# ------------------------
def get_mysql_connection():
    return mysql.connector.connect(**MYSQL_CONFIG)

@st.cache_data
def load_data():
    conn = get_mysql_connection()
    query = "SELECT category, upload_date, tokens, source FROM tokenised;"
    df = pd.read_sql(query, conn)
    conn.close()
    df['tokens'] = df['tokens'].apply(eval)
    df['upload_date'] = pd.to_datetime(df['upload_date'])
    return df

df = load_data()

# ------------------------
# ì‚¬ì´ë“œë°” í•„í„°
# ------------------------
st.sidebar.title("í•„í„°")
category = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬", df['category'].unique())
filtered_df = df[df['category'] == category]

# ------------------------
# íƒ­ êµ¬ì„±
# ------------------------
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "ğŸ“Š í‚¤ì›Œë“œ íŠ¸ë Œë“œ", "ğŸ“ˆ TF-IDF ë¶„ì„", "ğŸ•¸ï¸ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬", "ğŸ“‰ ì•„ì´í…œ ì¦ê°ë¥  ë¶„ì„", "ğŸ“° ë§¤ê±°ì§„ë³„ ë¶„ì„", "ğŸ–¼ï¸ ì¹´ë“œë‰´ìŠ¤", "ğŸ‘” MD ì¸ì‚¬ì´íŠ¸"
])


# ------------------------
# ğŸ“Š íƒ­ 1: íŠ¸ë Œë“œ
# ------------------------
with tab1:
    st.subheader(f"{category.upper()} ìƒìœ„ í‚¤ì›Œë“œ Top 20")
    all_tokens = [token for tokens in filtered_df['tokens'] for token in remove_stopwords(tokens)]
    token_counts = pd.Series(all_tokens).value_counts().head(20).reset_index()
    token_counts.columns = ['token', 'count']
    fig = px.bar(token_counts, x='token', y='count')
    st.plotly_chart(fig)

    st.subheader("ì›Œë“œí´ë¼ìš°ë“œ")
    wordcloud = WordCloud(
        font_path="C:/Windows/Fonts/malgun.ttf",
        background_color="white",
        width=800,
        height=400
    ).generate(' '.join(all_tokens))
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

# ------------------------
# ğŸ“ˆ íƒ­ 2: TF-IDF
# ------------------------
with tab2:
    st.subheader("TF-IDF í•µì‹¬ í‚¤ì›Œë“œ")
    filtered_df = filtered_df.reset_index(drop=True)
    article_idx = st.selectbox("ê¸°ì‚¬ ì„ íƒ (ì¸ë±ìŠ¤)", range(len(filtered_df)))
    
    docs = filtered_df['tokens'].apply(lambda x: ' '.join(remove_stopwords(x))).tolist()
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(docs)
    feature_names = vectorizer.get_feature_names_out()
    scores = tfidf_matrix[article_idx].toarray()[0]
    top_n = scores.argsort()[-20:][::-1]
    top_keywords = [(feature_names[i], scores[i]) for i in top_n if scores[i] > 0]

    if top_keywords:
        tk_df = pd.DataFrame(top_keywords, columns=['token', 'tfidf'])
        fig = px.bar(tk_df, x='token', y='tfidf')
        st.plotly_chart(fig)
    else:
        st.info("TF-IDF í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------
# ğŸ•¸ï¸ íƒ­ 3: ë„¤íŠ¸ì›Œí¬
# ------------------------
with tab3:
    st.subheader("í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”")

    font_path = "C:/Windows/Fonts/malgun.ttf"
    font_prop = fm.FontProperties(fname=font_path)
    font_name = font_prop.get_name()

    edge_counter = Counter()
    for tokens in filtered_df['tokens']:
        cleaned = remove_stopwords(tokens)
        unique_tokens = list(set(cleaned))
        if len(unique_tokens) >= 2:
            edge_counter.update(combinations(unique_tokens, 2))
    top_edges = edge_counter.most_common(30)

    G = nx.Graph()
    G.add_edges_from([(a, b, {'weight': w}) for (a, b), w in top_edges])

    pos = nx.spring_layout(G, k=0.5, seed=42)
    weights = [G[u][v]['weight'] for u, v in G.edges()]
    plt.figure(figsize=(10, 8))
    nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=600)
    nx.draw_networkx_edges(G, pos, edge_color=weights, edge_cmap=plt.cm.Blues, width=2)
    nx.draw_networkx_labels(G, pos, font_family=font_name, font_size=10)
    st.pyplot(plt.gcf())


# ------------------------
# ğŸ“‰ íƒ­ 4: ì•„ì´í…œ ì¦ê°ë¥  ë¶„ì„
# ------------------------
with tab4:
    st.subheader("ğŸ§¥ ì•„ì´í…œ íŠ¸ë Œë“œ ë³€í™” (ê¸°ê°„ë³„ ë¹„êµ)")

    # ê¸°ì¤€ ì„ íƒ
    keyword_type = st.radio("ê¸°ì¤€:", ["ì•„ì´í…œ", "ì»¬ëŸ¬", "ì†Œì¬", "í”„ë¦°íŠ¸", "ìŠ¤íƒ€ì¼"], horizontal=True)

    # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (ë™ì˜ì–´/ìœ ì‚¬ì–´ ë¬¶ê¸°)
    keyword_dict = {
        "ì•„ì´í…œ": ['ë“œë ˆìŠ¤', 'ì¬í‚·', 'íŒ¬ì¸ ', 'ìŠ¤ì»¤íŠ¸', 'ì½”íŠ¸', 'ë¸”ë¼ìš°ìŠ¤', 'ìºì£¼ì–¼ìƒì˜', 'ì í”„ìˆ˜íŠ¸', 'ë‹ˆíŠ¸ì›¨ì–´', 'ì…”ì¸ ', 'íƒ‘', 'ì²­ë°”ì§€', 'ìˆ˜ì˜ë³µ', 'ì í¼', 'ë² ìŠ¤íŠ¸', 'íŒ¨ë”©'],
        "ì»¬ëŸ¬": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ë² ì´ì§€', 'ë¸Œë¼ìš´', 'ê·¸ë ˆì´', 'ë¸”ë£¨', 'ìŠ¤ì¹´ì´ë¸”ë£¨', 'ë„¤ì´ë¹„', 'ì˜ë¡œìš°', 'í•‘í¬', 'ë ˆë“œ', 'ì¹´í‚¤', 'ë¼ë²¤ë”', 'ê·¸ë¦°', 'í¼í”Œ', 'ë¯¼íŠ¸', 'ì˜¤ë Œì§€', 'ì™€ì¸', 'ë©€í‹°'],
        "ì†Œì¬": ['í•©ì„±ì„¬ìœ ', 'ë©´', 'ê°€ì£½', 'ì‹œí°', 'ë‹ˆíŠ¸', 'ë°ë‹˜', 'ë ˆì´ìŠ¤', 'ì‹œí€¸/ê¸€ë¦¬í„°', 'ìºì‹œë¯¸ì–´/ìš¸', 'ìŠ¤ì›¨ì´ë“œ', 'ë²¨ë²³', 'ìŠ¤íŒë±ìŠ¤', 'í¼', 'íŠ¸ìœ„ë“œ', 'ë¹„ë‹/PVC', 'ë©”ì‹œ', 'ë¦°ë„¨', 'ìì¹´ë“œ', 'ì €ì§€', 'ì½”ë“€ë¡œì´', 'ë„¤ì˜¤í”„ë Œ', 'í”Œë¦¬ìŠ¤', 'ë¬´ìŠ¤íƒ•', 'ì•™ê³ ë¼', 'ì‹¤í¬'],
        "í”„ë¦°íŠ¸": ['ë¬´ì§€', 'í”Œë¡œëŸ´', 'ìŠ¤íŠ¸ë¼ì´í”„', 'ì²´í¬', 'ê·¸ë˜í”½', 'ë„íŠ¸', 'ë ˆí„°ë§', 'í˜ì´ì¦ë¦¬', 'í˜¸í”¼', 'ê·¸ë¼ë°ì´ì…˜', 'íƒ€ì´ë‹¤ì´', 'ì¹´ë¬´í”Œë¼ì¥¬/ì¹´ëª¨í”Œë¼ì¥¬', 'ì§€ê·¸ì¬ê·¸', 'ì§€ë¸Œë¼', 'í•´ê³¨', 'ë©€í‹°'],
        "ìŠ¤íƒ€ì¼": ['ì»¨íŠ¸ë¦¬', 'ì›¨ë”©', 'í”„ë ˆí”¼', 'íˆí”¼', 'ì•„ì›ƒë„ì–´', 'ë°€ë¦¬í„°ë¦¬', 'ë³µê³ ', 'í˜ë¯¸ë‹Œ', 'ìºì£¼ì–¼', 'ë§ˆë¦°', 'ì—ìŠ¤ë‹‰', 'ì˜¤í”¼ìŠ¤ë£©', 'íŒŒí‹°', 'ë¦¬ì¡°íŠ¸', 'í‘í¬']
    }

    keyword_aliases = {
        'ì‹œí€¸/ê¸€ë¦¬í„°': ['ì‹œí€¸', 'ê¸€ë¦¬í„°'],
        'ìºì‹œë¯¸ì–´/ìš¸': ['ìºì‹œë¯¸ì–´', 'ìš¸'],
        'ë¹„ë‹/PVC': ['ë¹„ë‹', 'pvc', 'PVC'],
        'ì¹´ë¬´í”Œë¼ì¥¬/ì¹´ëª¨í”Œë¼ì¥¬': ['ì¹´ë¬´í”Œë¼ì¥¬', 'ì¹´ëª¨í”Œë¼ì¥¬']
    }

    ITEM_KEYWORDS = keyword_dict[keyword_type]

    st.markdown("### ğŸ“† ë¶„ì„ ê¸°ê°„ ì„¤ì •")
    period_option = st.selectbox("ë¹„êµ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”", ['1ì£¼ì¼', '2ì£¼ì¼', '1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„', '2ë…„', 'ì§ì ‘ ì„¤ì •'])

    today = pd.to_datetime(datetime.today().date())
    if period_option == 'ì§ì ‘ ì„¤ì •':
        col1, col2 = st.columns(2)
        with col1:
            curr_start = st.date_input("í˜„ì¬ ì‹œì‘ì¼", value=today - timedelta(days=30))
            curr_end = st.date_input("í˜„ì¬ ì¢…ë£Œì¼", value=today)
        with col2:
            prev_start = st.date_input("ì´ì „ ì‹œì‘ì¼", value=today - timedelta(days=60))
            prev_end = st.date_input("ì´ì „ ì¢…ë£Œì¼", value=today - timedelta(days=31))
    else:
        delta_map = {
            '1ì£¼ì¼': 7,
            '2ì£¼ì¼': 14,
            '1ê°œì›”': 30,
            '3ê°œì›”': 90,
            '6ê°œì›”': 180,
            '1ë…„': 365,
            '2ë…„': 730
        }
        delta = timedelta(days=delta_map[period_option])
        curr_end = today
        curr_start = today - delta
        prev_end = curr_start - timedelta(days=1)
        prev_start = prev_end - delta + timedelta(days=1)

    # ê¸°ê°„ë³„ ë°ì´í„° í•„í„°ë§
    df_before = filtered_df[
        (filtered_df['upload_date'] >= pd.to_datetime(prev_start)) &
        (filtered_df['upload_date'] <= pd.to_datetime(prev_end))
    ]
    df_current = filtered_df[
        (filtered_df['upload_date'] >= pd.to_datetime(curr_start)) &
        (filtered_df['upload_date'] <= pd.to_datetime(curr_end))
    ]

    def count_items(df):
        all_tokens = [token for tokens in df['tokens'] for token in remove_stopwords(tokens)]
        counts = pd.Series(all_tokens).value_counts()
        result = {}
        for item in ITEM_KEYWORDS:
            if item in keyword_aliases:
                result[item] = sum(counts.get(alias, 0) for alias in keyword_aliases[item])
            else:
                result[item] = counts.get(item, 0)
        return result

    counts_current = count_items(df_current)
    counts_before = count_items(df_before)

    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    trend_df = pd.DataFrame({
        'item': ITEM_KEYWORDS,
        'í˜„ì¬ ì–¸ê¸‰ëŸ‰': [counts_current[i] for i in ITEM_KEYWORDS],
        'ì´ì „ ì–¸ê¸‰ëŸ‰': [counts_before[i] for i in ITEM_KEYWORDS]
    })
    trend_df['ì¦ê°ë¥ (%)'] = ((trend_df['í˜„ì¬ ì–¸ê¸‰ëŸ‰'] - trend_df['ì´ì „ ì–¸ê¸‰ëŸ‰']) /
                         trend_df['ì´ì „ ì–¸ê¸‰ëŸ‰'].replace(0, 1)) * 100

    # ì‹œê°í™” â‘  ì´ì „ vs í˜„ì¬ ì–¸ê¸‰ëŸ‰
    st.markdown("### ğŸ“Š ì´ì „ vs í˜„ì¬ ì–¸ê¸‰ëŸ‰ ë¹„êµ")
    fig_compare = px.bar(
        trend_df.melt(id_vars='item', value_vars=['ì´ì „ ì–¸ê¸‰ëŸ‰', 'í˜„ì¬ ì–¸ê¸‰ëŸ‰'], 
                      var_name='ê¸°ê°„', value_name='ì–¸ê¸‰ëŸ‰')
        .replace({
            'ì´ì „ ì–¸ê¸‰ëŸ‰': f"{prev_start.strftime('%Y.%m.%d')}~{prev_end.strftime('%Y.%m.%d')}",
            'í˜„ì¬ ì–¸ê¸‰ëŸ‰': f"{curr_start.strftime('%Y.%m.%d')}~{curr_end.strftime('%Y.%m.%d')}"
        }),
        x='item', y='ì–¸ê¸‰ëŸ‰', color='ê¸°ê°„',
        barmode='group', title=f"{keyword_type}ë³„ ì–¸ê¸‰ëŸ‰ (ì´ì „ vs í˜„ì¬)",
        labels={'item': keyword_type}
    )
    st.plotly_chart(fig_compare)

    # ì‹œê°í™” â‘¡ ì¦ê°ë¥ 
    st.markdown("### ğŸ“ˆ ì¦ê°ë¥ (%) ë³€í™”")
    fig_pct = px.bar(
        trend_df.sort_values("ì¦ê°ë¥ (%)", ascending=False),
        x="item", y="ì¦ê°ë¥ (%)", title=f"{keyword_type}ë³„ ì¦ê°ë¥ (%) ë³€í™”",
        labels={"item": keyword_type}
    )
    st.plotly_chart(fig_pct)


    # ì‹œê°í™” â‘¢ ë¼ì¸ê·¸ë˜í”„: ê¸°ê°„ë³„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸
    st.markdown("### ğŸ“‰ ê¸°ê°„ë³„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸ (ë¼ì¸ ê·¸ë˜í”„)")
    freq_option = st.selectbox("ê·¸ë˜í”„ ê¸°ì¤€ ê¸°ê°„ ì„ íƒ (ì¼ì ê¸°ì¤€)", ['1ì£¼ì¼', '1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„'], index=1)

    freq_days = {
        '1ì£¼ì¼': 7,
        '1ê°œì›”': 30,
        '3ê°œì›”': 90,
        '6ê°œì›”': 180,
        '1ë…„': 365
    }
    graph_delta = timedelta(days=freq_days[freq_option])
    graph_start = today - graph_delta
    df_graph = filtered_df[(filtered_df['upload_date'] >= graph_start) & (filtered_df['upload_date'] <= today)].copy()
    df_graph['upload_date'] = pd.to_datetime(df_graph['upload_date'])

    # ì§‘ê³„
    def count_weekly_mentions(df, keyword_list):
        df['week'] = df['upload_date'].dt.to_period('W').apply(lambda r: r.start_time)
        rows = []
        for week, group in df.groupby('week'):
            tokens = [token for tokens in group['tokens'] for token in remove_stopwords(tokens)]
            counts = pd.Series(tokens).value_counts()
            row = {'week': week}
            for kw in keyword_list:
                aliases = keyword_aliases.get(kw, [kw])
                row[kw] = sum(counts.get(a, 0) for a in aliases)
            rows.append(row)
        return pd.DataFrame(rows).sort_values('week')

    df_line = count_weekly_mentions(df_graph, ITEM_KEYWORDS)
    df_line_melted = df_line.melt(id_vars='week', var_name='í‚¤ì›Œë“œ', value_name='ì–¸ê¸‰ëŸ‰')

    # í‚¤ì›Œë“œ í•„í„° ì¶”ê°€
    selected_keywords = st.multiselect("í™•ì¸í•  í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ITEM_KEYWORDS, default=ITEM_KEYWORDS[:5])
    df_line_melted = df_line_melted[df_line_melted['í‚¤ì›Œë“œ'].isin(selected_keywords)]

    fig_line = px.line(
        df_line_melted,
        x='week', y='ì–¸ê¸‰ëŸ‰', color='í‚¤ì›Œë“œ',
        title=f"{keyword_type}ë³„ {freq_option}ê°„ ì£¼ê°„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸",
        labels={'week': 'ì£¼ì°¨'}
    )
    st.plotly_chart(fig_line)

    # í…Œì´ë¸” ì¶œë ¥
    st.dataframe(trend_df.sort_values("í˜„ì¬ ì–¸ê¸‰ëŸ‰", ascending=False), use_container_width=True)


# ------------------------
# ğŸ“° íƒ­ 5: ë§¤ê±°ì§„ ë¹„êµ
# ------------------------
with tab5:
    st.subheader("ğŸ“° ë§¤ê±°ì§„ë³„ íŠ¸ë Œë“œ ë¹„êµ ë¶„ì„")

    # ë§¤ê±°ì§„ ì„ íƒ
    magazines = sorted(filtered_df['source'].unique())
    selected_magazines = st.multiselect("ë§¤ê±°ì§„ ì„ íƒ", magazines, default=magazines[:3])

    # ë¶„ì„ ê¸°ê°„ ì„¤ì •
    date_range = st.selectbox("ë¶„ì„ ê¸°ê°„", ['1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„', 'ì „ì²´'] )
    today = pd.to_datetime(datetime.today().date())
    days_map = {'1ê°œì›”': 30, '3ê°œì›”': 90, '6ê°œì›”': 180, '1ë…„': 365}
    if date_range != 'ì „ì²´':
        start_date = today - timedelta(days=days_map[date_range])
        df_mag = filtered_df[(filtered_df['upload_date'] >= start_date)]
    else:
        df_mag = filtered_df.copy()

    df_mag = df_mag[df_mag['source'].isin(selected_magazines)]

    # ------------------------
    # 1ï¸âƒ£ ìƒìœ„ í‚¤ì›Œë“œ ë¹„êµ
    # ------------------------
    st.markdown("### ğŸ” ë§¤ê±°ì§„ë³„ ìƒìœ„ í‚¤ì›Œë“œ TOP 30")
    top_tokens_per_mag = {}
    for mag in selected_magazines:
        tokens = [token for tokens in df_mag[df_mag['source'] == mag]['tokens'] for token in remove_stopwords(tokens)]
        top_tokens_per_mag[mag] = pd.Series(tokens).value_counts().head(30)

    fig_top = go.Figure()
    for mag in selected_magazines:
        fig_top.add_trace(go.Bar(
            x=top_tokens_per_mag[mag].index,
            y=top_tokens_per_mag[mag].values,
            name=mag
        ))
    fig_top.update_layout(barmode='group', title="ë§¤ê±°ì§„ë³„ ìƒìœ„ í‚¤ì›Œë“œ ë¹„êµ", xaxis_title="í‚¤ì›Œë“œ", yaxis_title="ì–¸ê¸‰ëŸ‰")
    st.plotly_chart(fig_top)

    # ------------------------
    # 2ï¸âƒ£ ê³µí†µ vs ê³ ìœ  í‚¤ì›Œë“œ
    # ------------------------
    st.markdown("### ğŸ§¬ ê³µí†µ í‚¤ì›Œë“œ vs ê³ ìœ  í‚¤ì›Œë“œ")
    token_sets = {mag: set(top_tokens_per_mag[mag].index) for mag in selected_magazines}
    common_tokens = set.intersection(*token_sets.values()) if len(token_sets) > 1 else set()
    unique_tokens = {mag: token_sets[mag] - common_tokens for mag in selected_magazines}

    st.markdown("#### ğŸ§© ê³µí†µ í‚¤ì›Œë“œ")
    if common_tokens:
        tags_html = "".join([
            f"<span style='background:#E0F7FA; padding:6px 12px; border-radius:15px; margin:4px; display:inline-block;'>{kw}</span>"
            for kw in sorted(common_tokens)
        ])
        st.markdown(tags_html, unsafe_allow_html=True)
    else:
        st.markdown("-")

    st.markdown("#### âœ´ï¸ ë§¤ê±°ì§„ë³„ ê³ ìœ  í‚¤ì›Œë“œ")
    col_count = 3 if len(selected_magazines) >= 3 else len(selected_magazines)
    cols = st.columns(col_count)
    colors = ["#3CB371", "#1E90FF", "#FF6347", "#9370DB"]  # ì¹´ë“œ ìƒ‰ìƒ
    for idx, mag in enumerate(selected_magazines):
        with cols[idx % col_count]:
            st.markdown(f"""
                <div style='background-color:{colors[idx % len(colors)]}; padding: 10px 15px; border-radius: 10px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>
                    <h5 style='color:white; text-align:center; font-size:18px; margin-bottom:8px;'>{mag}</h5>
                    <ol style='color:white; font-size:15px;'>
                        {''.join(f'<li>{kw}</li>' for kw in sorted(unique_tokens[mag])[:10])}
                    </ol>
                </div>
            """, unsafe_allow_html=True)

    # ------------------------
    # 3ï¸âƒ£ TF-IDF ê³ ìœ  í‚¤ì›Œë“œ ë¶„ì„
    # ------------------------
    st.markdown("### ğŸ§  ë§¤ê±°ì§„ë³„ TF-IDF ëŒ€í‘œ í‚¤ì›Œë“œ")
    mag_groups = df_mag.groupby("source")['tokens'].apply(lambda x: [w for lst in x for w in remove_stopwords(lst)])
    docs = [" ".join(tokens) for tokens in mag_groups]
    tfidf = TfidfVectorizer()
    tfidf_matrix = tfidf.fit_transform(docs)
    feature_names = tfidf.get_feature_names_out()

    col_count = 3 if len(selected_magazines) >= 3 else len(selected_magazines)
    cols = st.columns(col_count)
    colors = ["#3CB371", "#1E90FF", "#FF6347", "#9370DB"]

    for i, mag in enumerate(mag_groups.index):
        row = tfidf_matrix[i].toarray().flatten()
        top_n = row.argsort()[-10:][::-1]
        keywords = [(feature_names[j], round(row[j], 4)) for j in top_n]
        with cols[i % col_count]:
            st.markdown(f"""
                <div style='background-color:{colors[i % len(colors)]}; padding: 10px 15px; border-radius: 10px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);'>
                    <h5 style='color:white; text-align:center; font-size:18px; margin-bottom:8px;'>{mag}</h5>
                    <ol style='color:white; font-size:15px;'>
                        {''.join(f'<li>{kw[0]} ({kw[1]})</li>' for kw in keywords)}
                    </ol>
                </div>
            """, unsafe_allow_html=True)

    # ------------------------
    # 4ï¸âƒ£ í‚¤ì›Œë“œë³„ ë§¤ê±°ì§„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸ (ë¼ì¸ê·¸ë˜í”„)
    # ------------------------
    st.markdown("### ğŸ“ˆ í‚¤ì›Œë“œë³„ ë§¤ê±°ì§„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸")
    focus_keywords_input = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value='ë¸”ë™, ì‹œì–´, í´ë˜ì‹')
    focus_keywords = [kw.strip() for kw in focus_keywords_input.split(',') if kw.strip()]

    df_mag['week'] = df_mag['upload_date'].dt.to_period('W').apply(lambda r: r.start_time)
    trend_rows = []

    for mag in selected_magazines:
        mag_df = df_mag[df_mag['source'] == mag]
        for week, group in mag_df.groupby('week'):
            all_tokens = [token for tokens in group['tokens'] for token in remove_stopwords(tokens)]
            token_counts = pd.Series(all_tokens).value_counts()
            for kw in focus_keywords:
                trend_rows.append({
                    'week': week,
                    'keyword': kw,
                    'count': token_counts.get(kw, 0),
                    'magazine': mag
                })

    df_kw_trend = pd.DataFrame(trend_rows)
    fig_kw_line = px.line(
        df_kw_trend,
        x='week', y='count', color='magazine',
        facet_col='keyword', facet_col_wrap=2,
        markers=True,
        title='ì„ íƒ í‚¤ì›Œë“œë³„ ë§¤ê±°ì§„ ì–¸ê¸‰ëŸ‰ ì¶”ì„¸',
        labels={'count': 'ì–¸ê¸‰ëŸ‰', 'week': 'ì£¼ì°¨', 'magazine': 'ë§¤ê±°ì§„'}
    )
    st.plotly_chart(fig_kw_line)


import requests
from bs4 import BeautifulSoup
import streamlit as st
import pandas as pd
import mysql.connector
from config import MYSQL_CONFIG

@st.cache_data
def load_magazine_articles():
    conn = get_mysql_connection()
    query = """
        SELECT title, upload_date, article_url
        FROM all_trends
        ORDER BY upload_date DESC
        LIMIT 30;
    """
    df = pd.read_sql(query, conn)
    conn.close()
    return df

@st.cache_data
def extract_og_image(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        og_img = soup.find("meta", property="og:image")
        return og_img["content"] if og_img else None
    except:
        return None

# íƒ­6 ë‚´ë¶€
with tab6:
    st.subheader("ğŸ–¼ï¸ ì¹´ë“œë‰´ìŠ¤")

    articles = load_magazine_articles()

    for i in range(0, len(articles), 3):
        cols = st.columns(3)
        for j in range(3):
            if i + j < len(articles):
                row = articles.iloc[i + j]
                with cols[j]:
                    img_url = extract_og_image(row['article_url'])
                    if img_url:
                        st.image(img_url, use_container_width=True)
                    else:
                        st.image("default.jpg", use_column_width=True)  # ê¸°ë³¸ ì´ë¯¸ì§€ ëŒ€ì²´ ê°€ëŠ¥
                    st.markdown(f"**[{row['title']}]({row['article_url']})**", unsafe_allow_html=True)
                    st.caption(f"ğŸ—“ï¸ {row['upload_date']}")




# ------------------------
# ğŸ‘” íƒ­ 7: MD ì¸ì‚¬ì´íŠ¸
# ------------------------
with tab7:
    st.subheader("ğŸ‘” íŒ¨ì…˜ MD ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ")

    # ê³µí†µ í‚¤ì›Œë“œ í™•ì¸ (ê¸°ì¡´ íƒ­5 ë¡œì§ ì¼ë¶€ í™œìš©)
    st.markdown("### ğŸ“‹ ë§¤ê±°ì§„ ê³µí†µ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„")
    
    # ë§¤ê±°ì§„ ì„ íƒ
    magazines = sorted(df['source'].unique())
    selected_magazines = st.multiselect("ë¶„ì„í•  ë§¤ê±°ì§„ ì„ íƒ", magazines, default=magazines[:3])
    
    # # ë¶„ì„ ê¸°ê°„ ì„¤ì •
    # date_range2 = st.selectbox("ë¶„ì„ ê¸°ê°„", ['1ê°œì›”', '3ê°œì›”', '6ê°œì›”', '1ë…„', 'ì „ì²´'])
    # today = pd.to_datetime(datetime.today().date())
    # days_map = {'1ê°œì›”': 30, '3ê°œì›”': 90, '6ê°œì›”': 180, '1ë…„': 365}
    
    if date_range  != 'ì „ì²´':
        start_date = today - timedelta(days=days_map[date_range])
        df_mag = df[(df['upload_date'] >= start_date)]
    else:
        df_mag = df.copy()
    
    df_mag = df_mag[df_mag['source'].isin(selected_magazines)]
    
    # ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ
    if selected_magazines:
        token_sets = {}
        for mag in selected_magazines:
            tokens = [token for tokens in df_mag[df_mag['source'] == mag]['tokens'] for token in remove_stopwords(tokens)]
            top_tokens = pd.Series(tokens).value_counts().head(50).index.tolist()  # ìƒìœ„ 50ê°œ í‚¤ì›Œë“œ ê¸°ì¤€
            token_sets[mag] = set(top_tokens)
        
        common_tokens = set.intersection(*token_sets.values()) if len(token_sets) > 1 else set()
        
        # ê³µí†µ í‚¤ì›Œë“œ í‘œì‹œ
        st.markdown("#### ğŸ§© ë§¤ê±°ì§„ ê³µí†µ í‚¤ì›Œë“œ")
        if common_tokens:
            tags_html = "".join([
                f"<span style='background:#E0F7FA; padding:6px 12px; border-radius:15px; margin:4px; display:inline-block;'>{kw}</span>"
                for kw in sorted(common_tokens)
            ])
            st.markdown(tags_html, unsafe_allow_html=True)
            
            # ë¶„ì„í•  í‚¤ì›Œë“œ ì„ íƒ
            keyword_to_analyze = st.selectbox("ë¶„ì„í•  ê³µí†µ í‚¤ì›Œë“œ ì„ íƒ", sorted(common_tokens))
            
            # ì‹œê°í™” ì˜µì…˜ ì„ íƒ
            visual_option = st.radio(
                "ë¶„ì„ ìœ í˜• ì„ íƒ", 
                ["ìƒí’ˆ ê¸°íš ì¸ì‚¬ì´íŠ¸", "ì‹œì¦Œ íŠ¸ë Œë“œ ë¶„ì„", "êµ¬ë§¤ ì „ëµ ì‹œë®¬ë ˆì´ì…˜"], 
                horizontal=True
            )
            
            # ì„ íƒí•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œ í•„í„°ë§
            filtered_docs = []
            for mag in selected_magazines:
                mag_df = df_mag[df_mag['source'] == mag]
                for _, row in mag_df.iterrows():
                    if keyword_to_analyze in remove_stopwords(row['tokens']):
                        filtered_docs.append(row)
            
            if filtered_docs:
                filtered_docs_df = pd.DataFrame(filtered_docs)
                
                # ì¹´í…Œê³ ë¦¬ ì •ì˜ (MD ë¶„ì„ìš©)
                categories = {
                    "ì•„ì´í…œ": ['ë“œë ˆìŠ¤', 'ì¬í‚·', 'íŒ¬ì¸ ', 'ìŠ¤ì»¤íŠ¸', 'ì½”íŠ¸', 'ë¸”ë¼ìš°ìŠ¤', 'ì í”„ìˆ˜íŠ¸', 'ë‹ˆíŠ¸ì›¨ì–´', 'ì…”ì¸ ', 'íƒ‘', 'ì²­ë°”ì§€', 'ìˆ˜ì˜ë³µ', 'ì í¼', 'ë² ìŠ¤íŠ¸', 'íŒ¨ë”©'],
                    "ì»¬ëŸ¬": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ë² ì´ì§€', 'ë¸Œë¼ìš´', 'ê·¸ë ˆì´', 'ë¸”ë£¨', 'ìŠ¤ì¹´ì´ë¸”ë£¨', 'ë„¤ì´ë¹„', 'ì˜ë¡œìš°', 'í•‘í¬', 'ë ˆë“œ', 'ì¹´í‚¤', 'ë¼ë²¤ë”', 'ê·¸ë¦°', 'í¼í”Œ', 'ë¯¼íŠ¸', 'ì˜¤ë Œì§€', 'ì™€ì¸', 'ë©€í‹°'],
                    "ì†Œì¬": ['í•©ì„±ì„¬ìœ ', 'ë©´', 'ê°€ì£½', 'ì‹œí°', 'ë‹ˆíŠ¸', 'ë°ë‹˜', 'ë ˆì´ìŠ¤', 'ì‹œí€¸', 'ê¸€ë¦¬í„°', 'ìºì‹œë¯¸ì–´', 'ìš¸', 'ìŠ¤ì›¨ì´ë“œ', 'ë²¨ë²³', 'ìŠ¤íŒë±ìŠ¤', 'í¼', 'íŠ¸ìœ„ë“œ', 'ë¹„ë‹', 'PVC', 'ë©”ì‹œ', 'ë¦°ë„¨', 'ìì¹´ë“œ', 'ì €ì§€', 'ì½”ë“€ë¡œì´'],
                    "ìŠ¤íƒ€ì¼": ['ì»¨íŠ¸ë¦¬', 'ì›¨ë”©', 'í”„ë ˆí”¼', 'íˆí”¼', 'ì•„ì›ƒë„ì–´', 'ë°€ë¦¬í„°ë¦¬', 'ë³µê³ ', 'í˜ë¯¸ë‹Œ', 'ìºì£¼ì–¼', 'ë§ˆë¦°', 'ì—ìŠ¤ë‹‰', 'ì˜¤í”¼ìŠ¤ë£©', 'íŒŒí‹°', 'ë¦¬ì¡°íŠ¸', 'í‘í¬']
                }
                
                # 1. ìƒí’ˆ ê¸°íš ì¸ì‚¬ì´íŠ¸
                if visual_option == "ìƒí’ˆ ê¸°íš ì¸ì‚¬ì´íŠ¸":
                    st.markdown(f"### '{keyword_to_analyze}' ìƒí’ˆ ê¸°íš ì¸ì‚¬ì´íŠ¸")
                    
                    # 1-1. ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„ (TF-IDF ê¸°ë°˜)
                    st.markdown("#### ğŸ·ï¸ ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„")
                    
                    # ì „ì²´ ì½”í¼ìŠ¤ì™€ í•„í„°ë§ëœ ë¬¸ì„œ ì¤€ë¹„
                    all_docs = [' '.join(remove_stopwords(tokens)) for tokens in df_mag['tokens']]
                    filtered_docs_text = [' '.join(remove_stopwords(tokens)) for tokens in filtered_docs_df['tokens']]
                    
                    # TF-IDF ê³„ì‚°
                    vectorizer = TfidfVectorizer(min_df=2)
                    vectorizer.fit(all_docs)
                    tfidf_matrix = vectorizer.transform(filtered_docs_text)
                    
                    # ë‹¨ì–´ë³„ í‰ê·  TF-IDF ê³„ì‚°
                    feature_names = vectorizer.get_feature_names_out()
                    tfidf_scores = {}
                    
                    for i in range(tfidf_matrix.shape[0]):
                        doc_vector = tfidf_matrix[i]
                        for idx, score in zip(doc_vector.indices, doc_vector.data):
                            word = feature_names[idx]
                            if word != keyword_to_analyze:
                                tfidf_scores[word] = tfidf_scores.get(word, 0) + score
                    
                    # í‰ê·  ê³„ì‚°
                    for word in tfidf_scores:
                        tfidf_scores[word] = tfidf_scores[word] / len(filtered_docs_text)
                    
                    # ìƒìœ„ í‚¤ì›Œë“œë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
                    top_keywords = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:30]
                    
                    # í‚¤ì›Œë“œë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
                    categorized_keywords = {cat: [] for cat in categories}
                    categorized_keywords["ê¸°íƒ€"] = []
                    
                    for word, score in top_keywords:
                        categorized = False
                        for cat, words in categories.items():
                            if word in words:
                                categorized_keywords[cat].append((word, score))
                                categorized = True
                                break
                        if not categorized:
                            categorized_keywords["ê¸°íƒ€"].append((word, score))
                    
                    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê²°ê³¼ í‘œì‹œ
                    cols = st.columns(len(categories) + 1)  # ì¹´í…Œê³ ë¦¬ + ê¸°íƒ€
                    
                    for i, (cat, keywords) in enumerate(categorized_keywords.items()):
                        with cols[i]:
                            st.markdown(f"**{cat}**")
                            if keywords:
                                for word, score in keywords[:5]:  # ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒìœ„ 5ê°œë§Œ
                                    st.markdown(f"- {word} ({score:.3f})")
                            else:
                                st.markdown("- ì—†ìŒ")
                    
                    # 1-2. ìƒí’ˆ ê¸°íš ì œì•ˆ ì‹œê°í™”
                    st.markdown("#### ğŸ“Š ìƒí’ˆ êµ¬ì„± ì œì•ˆ")
                    
                    # ì‹œê°í™” ë°ì´í„° ì¤€ë¹„
                    item_counts = {}
                    color_counts = {}
                    material_counts = {}
                    style_counts = {}
                    
                    # í† í° ë¹ˆë„ ê³„ì‚°
                    all_tokens = [token for tokens in filtered_docs_df['tokens'] for token in remove_stopwords(tokens)]
                    token_counts = pd.Series(all_tokens).value_counts()
                    
                    # ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
                    for item in categories["ì•„ì´í…œ"]:
                        item_counts[item] = token_counts.get(item, 0)
                    for color in categories["ì»¬ëŸ¬"]:
                        color_counts[color] = token_counts.get(color, 0)
                    for material in categories["ì†Œì¬"]:
                        material_counts[material] = token_counts.get(material, 0)
                    for style in categories["ìŠ¤íƒ€ì¼"]:
                        style_counts[style] = token_counts.get(style, 0)
                    
                    # ì•„ì´í…œë³„ ë¹„ì¤‘ íŒŒì´ì°¨íŠ¸
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ì•„ì´í…œ ë¶„í¬
                        item_df = pd.DataFrame({
                            'ì•„ì´í…œ': list(item_counts.keys()),
                            'ë¹ˆë„': list(item_counts.values())
                        }).sort_values('ë¹ˆë„', ascending=False).head(8)  # ìƒìœ„ 8ê°œë§Œ
                        
                        if item_df['ë¹ˆë„'].sum() > 0:
                            fig = px.pie(
                                item_df, values='ë¹ˆë„', names='ì•„ì´í…œ',
                                title=f"'{keyword_to_analyze}' ê´€ë ¨ ì£¼ìš” ì•„ì´í…œ êµ¬ì„±",
                                hole=0.4
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("ì•„ì´í…œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
                    with col2:
                        # ì»¬ëŸ¬ ë¶„í¬
                        color_df = pd.DataFrame({
                            'ì»¬ëŸ¬': list(color_counts.keys()),
                            'ë¹ˆë„': list(color_counts.values())
                        }).sort_values('ë¹ˆë„', ascending=False).head(8)  # ìƒìœ„ 8ê°œë§Œ
                        
                        if color_df['ë¹ˆë„'].sum() > 0:
                            fig = px.pie(
                                color_df, values='ë¹ˆë„', names='ì»¬ëŸ¬',
                                title=f"'{keyword_to_analyze}' ê´€ë ¨ ì£¼ìš” ì»¬ëŸ¬ êµ¬ì„±",
                                hole=0.4
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("ì»¬ëŸ¬ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
                    # ì†Œì¬ ë° ìŠ¤íƒ€ì¼ ë°” ì°¨íŠ¸
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ì†Œì¬ ë¶„í¬
                        material_df = pd.DataFrame({
                            'ì†Œì¬': list(material_counts.keys()),
                            'ë¹ˆë„': list(material_counts.values())
                        }).sort_values('ë¹ˆë„', ascending=False).head(8)  # ìƒìœ„ 8ê°œë§Œ
                        
                        if material_df['ë¹ˆë„'].sum() > 0:
                            fig = px.bar(
                                material_df, x='ì†Œì¬', y='ë¹ˆë„',
                                title=f"'{keyword_to_analyze}' ê´€ë ¨ ì£¼ìš” ì†Œì¬"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("ì†Œì¬ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
                    with col2:
                        # ìŠ¤íƒ€ì¼ ë¶„í¬
                        style_df = pd.DataFrame({
                            'ìŠ¤íƒ€ì¼': list(style_counts.keys()),
                            'ë¹ˆë„': list(style_counts.values())
                        }).sort_values('ë¹ˆë„', ascending=False).head(8)  # ìƒìœ„ 8ê°œë§Œ
                        
                        if style_df['ë¹ˆë„'].sum() > 0:
                            fig = px.bar(
                                style_df, x='ìŠ¤íƒ€ì¼', y='ë¹ˆë„',
                                title=f"'{keyword_to_analyze}' ê´€ë ¨ ì£¼ìš” ìŠ¤íƒ€ì¼"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("ìŠ¤íƒ€ì¼ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
                    # 1-3. MD í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¹´ë“œ
                    st.markdown("#### ğŸ’¡ MD í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
                    
                    # ìƒìœ„ ì•„ì´í…œ, ì»¬ëŸ¬, ì†Œì¬, ìŠ¤íƒ€ì¼ ì¶”ì¶œ
                    top_items = item_df['ì•„ì´í…œ'].tolist()[:3] if not item_df.empty and item_df['ë¹ˆë„'].sum() > 0 else []
                    top_colors = color_df['ì»¬ëŸ¬'].tolist()[:3] if not color_df.empty and color_df['ë¹ˆë„'].sum() > 0 else []
                    top_materials = material_df['ì†Œì¬'].tolist()[:3] if not material_df.empty and material_df['ë¹ˆë„'].sum() > 0 else []
                    top_styles = style_df['ìŠ¤íƒ€ì¼'].tolist()[:3] if not style_df.empty and style_df['ë¹ˆë„'].sum() > 0 else []
                    
                    # ì¸ì‚¬ì´íŠ¸ ì¹´ë“œ ìƒì„±
                    cols = st.columns(2)
                    
                    with cols[0]:
                        st.markdown(f"""
                        <div style='background-color:#f0f7ff; padding:20px; border-radius:10px; border-left:5px solid #1E88E5;'>
                            <h4 style='color:#1565C0; margin-top:0;'>ìƒí’ˆ êµ¬ì„± ì œì•ˆ</h4>
                            <p><strong>ì£¼ë ¥ ì•„ì´í…œ:</strong> {', '.join(top_items) if top_items else 'ë°ì´í„° ë¶€ì¡±'}</p>
                            <p><strong>ì£¼ìš” ì»¬ëŸ¬ì›¨ì´:</strong> {', '.join(top_colors) if top_colors else 'ë°ì´í„° ë¶€ì¡±'}</p>
                            <p><strong>ê¶Œì¥ ì†Œì¬:</strong> {', '.join(top_materials) if top_materials else 'ë°ì´í„° ë¶€ì¡±'}</p>
                            <p><strong>ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ë§:</strong> {', '.join(top_styles) if top_styles else 'ë°ì´í„° ë¶€ì¡±'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with cols[1]:
                        # ì„ íƒì : ê´€ë ¨ ë¬¸ì„œ ìˆ˜, ì‹œê°„ì  íŠ¸ë Œë“œ ë“± ì¶”ê°€ ì •ë³´
                        st.markdown(f"""
                        <div style='background-color:#fff8e1; padding:20px; border-radius:10px; border-left:5px solid #FFA000;'>
                            <h4 style='color:#F57C00; margin-top:0;'>íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸</h4>
                            <p><strong>ê´€ë ¨ ê¸°ì‚¬ ìˆ˜:</strong> {len(filtered_docs)}</p>
                            <p><strong>ì–¸ê¸‰ ë§¤ê±°ì§„:</strong> {', '.join(filtered_docs_df['source'].unique())}</p>
                            <p><strong>ìµœê·¼ ê²Œì¬ì¼:</strong> {filtered_docs_df['upload_date'].max().strftime('%Y-%m-%d')}</p>
                            <p><strong>ì¶”ì²œ MD ì•¡ì…˜:</strong> {'ë¹ ë¥¸ ì‹œì¦Œ ë„ì… ê²€í† ' if len(filtered_docs) > 5 else 'íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                
                # 2. ì‹œì¦Œ íŠ¸ë Œë“œ ë¶„ì„
                elif visual_option == "ì‹œì¦Œ íŠ¸ë Œë“œ ë¶„ì„":
                    st.markdown(f"### '{keyword_to_analyze}' ì‹œì¦Œ íŠ¸ë Œë“œ ë¶„ì„")
                    
                    # 2-1. ê¸°ê°„ë³„ ì–¸ê¸‰ ì¶”ì´
                    st.markdown("#### ğŸ“ˆ ê¸°ê°„ë³„ ì–¸ê¸‰ ì¶”ì´")
                    
                    # ì›”ë³„ ì–¸ê¸‰ëŸ‰ ì¶”ì´
                    filtered_docs_df['month'] = filtered_docs_df['upload_date'].dt.to_period('M')
                    monthly_counts = filtered_docs_df.groupby('month').size().reset_index(name='count')
                    monthly_counts['month_str'] = monthly_counts['month'].astype(str)
                    
                    fig = px.line(
                        monthly_counts, x='month_str', y='count',
                        title=f"'{keyword_to_analyze}' ì›”ë³„ ì–¸ê¸‰ ì¶”ì´",
                        markers=True
                    )
                    st.plotly_chart(fig)
                    
                    # 2-2. ë§¤ê±°ì§„ë³„ ê´€ì‹¬ë„ ë¹„êµ
                    st.markdown("#### ğŸ” ë§¤ê±°ì§„ë³„ ê´€ì‹¬ë„ ë¹„êµ")
                    
                    magazine_counts = filtered_docs_df['source'].value_counts().reset_index()
                    magazine_counts.columns = ['ë§¤ê±°ì§„', 'ì–¸ê¸‰ ìˆ˜']
                    
                    fig = px.bar(
                        magazine_counts, x='ë§¤ê±°ì§„', y='ì–¸ê¸‰ ìˆ˜',
                        title=f"'{keyword_to_analyze}' ë§¤ê±°ì§„ë³„ ê´€ì‹¬ë„"
                    )
                    st.plotly_chart(fig)
                    
                    # 2-3. ì‹œì¦Œë³„ ì—°ê´€ í‚¤ì›Œë“œ ë¹„êµ
                    st.markdown("#### ğŸ—“ï¸ ì‹œì¦Œë³„ ì—°ê´€ í‚¤ì›Œë“œ ë¹„êµ")
                    
                    # ì‹œì¦Œ ì •ì˜ (ë´„/ì—¬ë¦„/ê°€ì„/ê²¨ìš¸)
                    def get_season(month):
                        if month in [3, 4, 5]:
                            return 'ë´„'
                        elif month in [6, 7, 8]:
                            return 'ì—¬ë¦„'
                        elif month in [9, 10, 11]:
                            return 'ê°€ì„'
                        else:  # 12, 1, 2
                            return 'ê²¨ìš¸'
                    
                    filtered_docs_df['season'] = filtered_docs_df['upload_date'].dt.month.apply(get_season)
                    
                    # ì‹œì¦Œë³„ í† í° ì¶”ì¶œ
                    season_tokens = {}
                    for season, group in filtered_docs_df.groupby('season'):
                        tokens = [token for tokens in group['tokens'] for token in remove_stopwords(tokens)]
                        tokens = [t for t in tokens if t != keyword_to_analyze]  # ë¶„ì„ í‚¤ì›Œë“œ ì œì™¸
                        season_tokens[season] = pd.Series(tokens).value_counts().head(10)
                    
                    # ì‹œì¦Œì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹œê°í™”
                    if season_tokens:
                        # ë´„/ì—¬ë¦„/ê°€ì„/ê²¨ìš¸ ì»¬ëŸ¬ ì •ì˜
                        season_colors = {
                            'ë´„': '#4CAF50',
                            'ì—¬ë¦„': '#F44336',
                            'ê°€ì„': '#FF9800',
                            'ê²¨ìš¸': '#2196F3'
                        }
                        
                        fig = go.Figure()
                        
                        for season, counts in season_tokens.items():
                            if not counts.empty:
                                fig.add_trace(go.Bar(
                                    x=counts.index,
                                    y=counts.values,
                                    name=season,
                                    marker_color=season_colors.get(season, '#9E9E9E')
                                ))
                        
                        fig.update_layout(
                            barmode='group',
                            title=f"'{keyword_to_analyze}' ì‹œì¦Œë³„ ì—°ê´€ í‚¤ì›Œë“œ Top 10",
                            xaxis_title="ì—°ê´€ í‚¤ì›Œë“œ",
                            yaxis_title="ì–¸ê¸‰ ë¹ˆë„"
                        )
                        st.plotly_chart(fig)
                        
                        # 2-4. ì‹œì¦Œë³„ MD ì¶”ì²œ ì¹´ë“œ
                        st.markdown("#### ğŸ’¼ ì‹œì¦Œë³„ MD ì•¡ì…˜ í”Œëœ")
                        
                        # ê° ì‹œì¦Œë³„ ìƒìœ„ ì•„ì´í…œ/ì»¬ëŸ¬
                        season_insights = {}
                        
                        for season, group in filtered_docs_df.groupby('season'):
                            season_all_tokens = [token for tokens in group['tokens'] for token in remove_stopwords(tokens)]
                            token_counts = pd.Series(season_all_tokens).value_counts()
                            
                            # ì•„ì´í…œ, ì»¬ëŸ¬ ì¶”ì¶œ
                            season_items = [item for item in categories["ì•„ì´í…œ"] if item in token_counts]
                            season_items = sorted(season_items, key=lambda x: token_counts.get(x, 0), reverse=True)[:3]
                            
                            season_colors = [color for color in categories["ì»¬ëŸ¬"] if color in token_counts]
                            season_colors = sorted(season_colors, key=lambda x: token_counts.get(x, 0), reverse=True)[:3]
                            
                            season_insights[season] = {
                                'items': season_items,
                                'colors': season_colors
                            }
                        
                        # ì‹œì¦Œ ì¹´ë“œ í‘œì‹œ
                        seasons = ['ë´„', 'ì—¬ë¦„', 'ê°€ì„', 'ê²¨ìš¸']
                        cols = st.columns(4)
                        
                        for i, season in enumerate(seasons):
                            insight = season_insights.get(season, {'items': [], 'colors': []})
                            
                            with cols[i]:
                                st.markdown(f"""
                                <div style='background-color:{season_colors.get(season, '#E0E0E0')}22; padding:15px; border-radius:10px; border-left:5px solid {season_colors.get(season, '#9E9E9E')};'>
                                    <h4 style='color:{season_colors.get(season, '#757575')}; margin-top:0;'>{season} ì‹œì¦Œ</h4>
                                    <p><strong>ì£¼ìš” ì•„ì´í…œ:</strong><br> {', '.join(insight['items']) if insight['items'] else 'ë°ì´í„° ë¶€ì¡±'}</p>
                                    <p><strong>ì¶”ì²œ ì»¬ëŸ¬:</strong><br> {', '.join(insight['colors']) if insight['colors'] else 'ë°ì´í„° ë¶€ì¡±'}</p>
                                    <p><strong>ì‹œì¦Œ ë¹„ì¤‘:</strong><br> {len(filtered_docs_df[filtered_docs_df['season'] == season])/len(filtered_docs_df)*100:.1f}%</p>
                                </div>
                                """, unsafe_allow_html=True)
                    else:
                        st.info("ì‹œì¦Œë³„ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # 3. êµ¬ë§¤ ì „ëµ ì‹œë®¬ë ˆì´ì…˜
                elif visual_option == "êµ¬ë§¤ ì „ëµ ì‹œë®¬ë ˆì´ì…˜":
                    st.markdown(f"### '{keyword_to_analyze}' êµ¬ë§¤ ì „ëµ ì‹œë®¬ë ˆì´ì…˜")
                    
                    # 3-1. ì¸í„°ë™í‹°ë¸Œ êµ¬ë§¤ ì‹œë®¬ë ˆì´í„°
                    st.markdown("#### ğŸ›’ êµ¬ë§¤ ë¬¼ëŸ‰ ì‹œë®¬ë ˆì´í„°")
                    
                    # ê¸°ë³¸ ì„¤ì •ê°’
                    total_budget = st.slider("ì´ êµ¬ë§¤ ì˜ˆì‚° (ë°±ë§Œì›)", 10, 500, 100, 10)
                    expected_sales = st.slider("ì˜ˆìƒ íŒë§¤ìœ¨ (%)", 30, 100, 70, 5)
                    
                    # ì•„ì´í…œë³„ ë¬¼ëŸ‰ ë¹„ì¤‘ ê³„ì‚°
                    all_tokens = [token for tokens in filtered_docs_df['tokens'] for token in remove_stopwords(tokens)]
                    token_counts = pd.Series(all_tokens).value_counts()
                    
                    # ì•„ì´í…œ ëª©ë¡ ì¶”ì¶œ
                    items = [item for item in categories["ì•„ì´í…œ"] if token_counts.get(item, 0) > 0]
                    items = sorted(items, key=lambda x: token_counts.get(x, 0), reverse=True)[:6]  # ìƒìœ„ 6ê°œ ì•„ì´í…œ
                    
                    if items:
                        # ì•„ì´í…œë³„ ê¸°ë³¸ êµ¬ë§¤ ë¹„ì¤‘
                        item_weights = {item: token_counts.get(item, 0) for item in items}
                        total_weight = sum(item_weights.values())
                        item_ratios = {item: weight/total_weight for item, weight in item_weights.items()}
                        
                        # ì•„ì´í…œë³„ ì˜ˆìƒ íŒë§¤ê°€
                        st.markdown("**ì•„ì´í…œë³„ ì˜ˆìƒ íŒë§¤ê°€ ì„¤ì • (ë§Œì›)**")
                        price_cols = st.columns(len(items))
                        item_prices = {}
                        
                        for i, item in enumerate(items):
                            with price_cols[i]:
                                item_prices[item] = st.number_input(
                                    item, min_value=1, max_value=100, value=10+i*5, step=1
                                )
                        
                        # ì•„ì´í…œë³„ ë¬¼ëŸ‰ ì¡°ì •
                        st.markdown("**ì•„ì´í…œë³„ êµ¬ë§¤ ë¹„ì¤‘ ì¡°ì • (%)**")
                        ratio_cols = st.columns(len(items))
                        adjusted_ratios = {}
                        
                        for i, item in enumerate(items):
                            with ratio_cols[i]:
                                default_pct = int(item_ratios[item] * 100)
                                adjusted_ratios[item] = st.slider(
                                    item, min_value=5, max_value=50, value=default_pct, step=5
                                ) / 100
                        
                        # ë¹„ì¤‘ ì •ê·œí™”
                        total_adjusted = sum(adjusted_ratios.values())
                        normalized_ratios = {item: ratio/total_adjusted for item, ratio in adjusted_ratios.items()}
                        
                        # êµ¬ë§¤ ê³„íš ê³„ì‚°
                        st.markdown("#### ğŸ“‹ êµ¬ë§¤ ê³„íš ë¶„ì„")
                        
                        # ì•„ì´í…œë³„ êµ¬ë§¤ ê¸ˆì•¡
                        item_budgets = {item: total_budget * ratio for item, ratio in normalized_ratios.items()}
                        
                        # ì•„ì´í…œë³„ êµ¬ë§¤ ìˆ˜ëŸ‰
                        item_quantities = {item: int(budget / (item_prices[item] * 0.1)) for item, budget in item_budgets.items()}
                        
                        # ì˜ˆìƒ ë§¤ì¶œ ë° ì´ìµ
                        total_quantity = sum(item_quantities.values())
                        expected_sold = total_quantity * (expected_sales / 100)
                        total_sales = sum(item_quantities[item] * item_prices[item] * (expected_sales / 100) for item in items)
                        
                        # ê²°ê³¼ í‘œì‹œ
                        plan_df = pd.DataFrame({
                            'ì•„ì´í…œ': list(item_quantities.keys()),
                            'íŒë§¤ê°€(ë§Œì›)': [item_prices[item] for item in items],
                            'êµ¬ë§¤ë¹„ì¤‘(%)': [normalized_ratios[item] * 100 for item in items],
                            'êµ¬ë§¤ê¸ˆì•¡(ë§Œì›)': [item_budgets[item] / 10 for item in items],
                            'êµ¬ë§¤ìˆ˜ëŸ‰(ê°œ)': list(item_quantities.values()),
                            'ì˜ˆìƒíŒë§¤(ê°œ)': [item_quantities[item] * (expected_sales / 100) for item in items],
                            'ì˜ˆìƒë§¤ì¶œ(ë§Œì›)': [item_quantities[item] * item_prices[item] * (expected_sales / 100) for item in items]
                        })
                        
                        st.dataframe(plan_df, use_container_width=True)
                        
                        # 3-2. ì‹œê°í™”: êµ¬ë§¤ ê³„íš
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # êµ¬ë§¤ ìˆ˜ëŸ‰ íŒŒì´ ì°¨íŠ¸
                            fig = px.pie(
                                plan_df, values='êµ¬ë§¤ìˆ˜ëŸ‰(ê°œ)', names='ì•„ì´í…œ',
                                title="ì•„ì´í…œë³„ êµ¬ë§¤ ìˆ˜ëŸ‰ ë¹„ì¤‘"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            # ì˜ˆìƒ ë§¤ì¶œ íŒŒì´ ì°¨íŠ¸
                            fig = px.pie(
                                plan_df, values='ì˜ˆìƒë§¤ì¶œ(ë§Œì›)', names='ì•„ì´í…œ',
                                title="ì•„ì´í…œë³„ ì˜ˆìƒ ë§¤ì¶œ ë¹„ì¤‘"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # 3-3. êµ¬ë§¤ ìš”ì•½ ë° KPI
                        st.markdown("#### ğŸ“Š êµ¬ë§¤ ì „ëµ ìš”ì•½")
                        
                        kpi_cols = st.columns(4)
                        
                        with kpi_cols[0]:
                            st.metric(
                                label="ì´ êµ¬ë§¤ ìˆ˜ëŸ‰",
                                value=f"{int(total_quantity)}ê°œ"
                            )
                        
                        with kpi_cols[1]:
                            st.metric(
                                label="ì˜ˆìƒ íŒë§¤ ìˆ˜ëŸ‰",
                                value=f"{int(expected_sold)}ê°œ"
                            )
                        
                        with kpi_cols[2]:
                            st.metric(
                                label="íˆ¬ì… ì˜ˆì‚°",
                                value=f"{total_budget:.1f}ë°±ë§Œì›"
                            )
                        
                        with kpi_cols[3]:
                            st.metric(
                                label="ì˜ˆìƒ ë§¤ì¶œ",
                                value=f"{total_sales:.1f}ë§Œì›",
                                delta=f"{total_sales - (total_budget * 100):.1f}ë§Œì›"
                            )
                        
                        # 3-4. êµ¬ë§¤ ì „ëµ ì¶”ì²œ ì¹´ë“œ
                        st.markdown("#### ğŸ’¡ MD êµ¬ë§¤ ì „ëµ ì¶”ì²œ")
                        
                        # ê°€ì¥ ìˆ˜ìµì„± ë†’ì€ ì•„ì´í…œ
                        profit_per_item = plan_df['ì˜ˆìƒë§¤ì¶œ(ë§Œì›)'] / plan_df['êµ¬ë§¤ê¸ˆì•¡(ë§Œì›)']
                        plan_df['ìˆ˜ìµì„±'] = profit_per_item
                        best_profit_item = plan_df.loc[profit_per_item.idxmax(), 'ì•„ì´í…œ']
                        
                        # ë¹ ë¥¸ íšŒì „ ì˜ˆìƒ ì•„ì´í…œ
                        best_rotation_item = plan_df.loc[plan_df['ì˜ˆìƒíŒë§¤(ê°œ)'].idxmax(), 'ì•„ì´í…œ']
                        
                        # ì•ˆì „ ì¬ê³  ë¹„ìœ¨
                        safety_stock_pct = 20  # ì˜ˆ: 20%
                        
                        st.markdown(f"""
                        <div style='background-color:#e8f5e9; padding:20px; border-radius:10px; border-left:5px solid #4CAF50;'>
                            <h4 style='color:#2E7D32; margin-top:0;'>MD êµ¬ë§¤ ì „ëµ ì¸ì‚¬ì´íŠ¸</h4>
                            <p>ğŸ”¹ <strong>ì¤‘ì  êµ¬ë§¤ ì•„ì´í…œ:</strong> <span style='color:#1B5E20;'>{best_profit_item}</span> (ìˆ˜ìµì„± {plan_df['ìˆ˜ìµì„±'].max():.2f}ë°°)</p>
                            <p>ğŸ”¹ <strong>ë¹ ë¥¸ íšŒì „ ì˜ˆìƒ:</strong> <span style='color:#1B5E20;'>{best_rotation_item}</span></p>
                            <p>ğŸ”¹ <strong>ì•ˆì „ ì¬ê³  ì¶”ì²œ:</strong> ì¸ê¸° ì•„ì´í…œ <span style='color:#1B5E20;'>{safety_stock_pct}%</span> ì¶”ê°€ í™•ë³´</p>
                            <p>ğŸ”¹ <strong>í‚¤ì›Œë“œ í¬ì§€ì…”ë‹:</strong> {keyword_to_analyze} ê´€ë ¨ ìƒí’ˆêµ° <span style='color:#1B5E20;'>ìƒìŠ¹ì„¸</span> ì˜ˆìƒ</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # 3-5. ê²½ìŸ ë¶„ì„ (ì„ íƒì )
                        st.markdown("#### ğŸ† ì‹œì¥ ë¹„êµ ë¶„ì„")
                        
                        # ë§¤ê±°ì§„ë³„ ê´€ì‹¬ë„ íˆíŠ¸ë§µ
                        st.markdown("**ë§¤ê±°ì§„ë³„ ê´€ì‹¬ë„ íˆíŠ¸ë§µ**")
                        
                        # ì•„ì´í…œë³„ ë§¤ê±°ì§„ ê´€ì‹¬ë„ ê³„ì‚°
                        item_magazine_matrix = []
                        
                        for item in items[:4]:  # ìƒìœ„ 4ê°œ ì•„ì´í…œë§Œ
                            for mag in selected_magazines:
                                mag_docs = filtered_docs_df[filtered_docs_df['source'] == mag]
                                mag_tokens = [token for tokens in mag_docs['tokens'] for token in remove_stopwords(tokens)]
                                count = mag_tokens.count(item)
                                item_magazine_matrix.append({
                                    'ì•„ì´í…œ': item,
                                    'ë§¤ê±°ì§„': mag,
                                    'ì–¸ê¸‰ ìˆ˜': count
                                })
                        
                        if item_magazine_matrix:
                            heatmap_df = pd.DataFrame(item_magazine_matrix)
                            pivot_df = heatmap_df.pivot(index='ì•„ì´í…œ', columns='ë§¤ê±°ì§„', values='ì–¸ê¸‰ ìˆ˜').fillna(0)
                            
                            fig = px.imshow(
                                pivot_df,
                                labels=dict(x="ë§¤ê±°ì§„", y="ì•„ì´í…œ", color="ì–¸ê¸‰ ìˆ˜"),
                                x=pivot_df.columns,
                                y=pivot_df.index,
                                title=f"'{keyword_to_analyze}' ì•„ì´í…œë³„ ë§¤ê±°ì§„ ê´€ì‹¬ë„",
                                color_continuous_scale='Viridis'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("ë§¤ê±°ì§„ë³„ ì•„ì´í…œ ê´€ì‹¬ë„ë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("êµ¬ë§¤ ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ì•„ì´í…œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                st.info(f"'{keyword_to_analyze}'ê°€ í¬í•¨ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê³µí†µ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë§¤ê±°ì§„ì´ë‚˜ ê¸°ê°„ì„ ì„ íƒí•´ë³´ì„¸ìš”.")
    else:
        st.warning("ë¶„ì„ì„ ìœ„í•´ ìµœì†Œ ë‘ ê°œ ì´ìƒì˜ ë§¤ê±°ì§„ì„ ì„ íƒí•˜ì„¸ìš”.")
    
    # MD íŠ¸ë Œë“œ ì›Œì¹˜
    st.markdown("### ğŸ”® MD íŠ¸ë Œë“œ ì›Œì¹˜")
    
    # ìƒìŠ¹ì„¸ í‚¤ì›Œë“œ ë¶„ì„
    st.markdown("#### ğŸ“ˆ ê¸‰ìƒìŠ¹ í‚¤ì›Œë“œ (ìµœê·¼ 30ì¼)")
    
    # ë‚ ì§œ ê¸°ì¤€ ì •ì˜
    today = pd.to_datetime(datetime.today().date())
    last_30days = today - timedelta(days=30)
    last_60days = today - timedelta(days=60)
    
    # ìµœê·¼ 30ì¼ vs ì´ì „ 30ì¼ ë°ì´í„°
    df_recent = df[(df['upload_date'] >= last_30days) & (df['upload_date'] <= today)]
    df_previous = df[(df['upload_date'] >= last_60days) & (df['upload_date'] < last_30days)]
    
    # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
    recent_tokens = [token for tokens in df_recent['tokens'] for token in remove_stopwords(tokens)]
    previous_tokens = [token for tokens in df_previous['tokens'] for token in remove_stopwords(tokens)]
    
    recent_counts = pd.Series(recent_tokens).value_counts()
    previous_counts = pd.Series(previous_tokens).value_counts()
    
    # ìƒìŠ¹ë¥  ê³„ì‚°
    growth_data = []
    for keyword, recent_count in recent_counts.items():
        if keyword in previous_counts:
            previous_count = previous_counts[keyword]
            if previous_count > 0:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                growth_pct = ((recent_count - previous_count) / previous_count) * 100
                if recent_count >= 5:  # ìµœì†Œ ì–¸ê¸‰ 5íšŒ ì´ìƒ
                    growth_data.append({
                        'í‚¤ì›Œë“œ': keyword,
                        'ìµœê·¼ ë¹ˆë„': recent_count,
                        'ì´ì „ ë¹ˆë„': previous_count,
                        'ìƒìŠ¹ë¥ (%)': growth_pct
                    })
    
    growth_df = pd.DataFrame(growth_data)
    
    if not growth_df.empty:
        # ìƒìœ„ 10ê°œ ìƒìŠ¹ í‚¤ì›Œë“œ
        top_growth = growth_df.sort_values('ìƒìŠ¹ë¥ (%)', ascending=False).head(10)
        
        fig = px.bar(
            top_growth, x='í‚¤ì›Œë“œ', y='ìƒìŠ¹ë¥ (%)',
            title="ìµœê·¼ 30ì¼ê°„ ê¸‰ìƒìŠ¹ í‚¤ì›Œë“œ Top 10",
            color='ìƒìŠ¹ë¥ (%)',
            color_continuous_scale='Reds',
            hover_data=['ìµœê·¼ ë¹ˆë„', 'ì´ì „ ë¹ˆë„']
        )
        st.plotly_chart(fig)
        
        # ìƒìŠ¹ í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        rising_categories = {cat: [] for cat in categories}
        rising_categories["ê¸°íƒ€"] = []
        
        for _, row in top_growth.iterrows():
            keyword = row['í‚¤ì›Œë“œ']
            categorized = False
            for cat, words in categories.items():
                if keyword in words:
                    rising_categories[cat].append((keyword, row['ìƒìŠ¹ë¥ (%)']))
                    categorized = True
                    break
            if not categorized:
                rising_categories["ê¸°íƒ€"].append((keyword, row['ìƒìŠ¹ë¥ (%)']))
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒìŠ¹ í‚¤ì›Œë“œ í‘œì‹œ
        st.markdown("#### ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ê¸‰ìƒìŠ¹ íŠ¸ë Œë“œ")
        
        cat_cols = st.columns(3)
        cat_colors = {
            "ì•„ì´í…œ": "#5C6BC0",  # ì¸ë””ê³ 
            "ì»¬ëŸ¬": "#26A69A",    # í‹¸
            "ì†Œì¬": "#FFA726",    # ì˜¤ë Œì§€
            "ìŠ¤íƒ€ì¼": "#EC407A",   # í•‘í¬
            "ê¸°íƒ€": "#78909C"     # ë¸”ë£¨ê·¸ë ˆì´
        }
        
        i = 0
        for cat, keywords in rising_categories.items():
            if keywords:
                with cat_cols[i % 3]:
                    st.markdown(f"""
                    <div style='background-color:{cat_colors.get(cat, "#E0E0E0")}22; padding:15px; border-radius:10px; border-left:5px solid {cat_colors.get(cat, "#9E9E9E")};'>
                        <h4 style='color:{cat_colors.get(cat, "#757575")}; margin-top:0;'>{cat}</h4>
                        {"".join([f"<p><strong>{kw}</strong>: â†‘ {pct:.1f}%</p>" for kw, pct in keywords[:3]])}
                    </div>
                    """, unsafe_allow_html=True)
                    i += 1
    else:
        st.info("ìƒìŠ¹ì„¸ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # MD ì¶”ì²œ ì¡°í•©
    st.markdown("#### âœ¨ MD ì¶”ì²œ íŠ¸ë Œë“œ ì¡°í•©")
    
    # ë§ì´ í•¨ê»˜ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ ì¡°í•© ì°¾ê¸°
    edge_counter = Counter()
    for tokens in df_recent['tokens']:
        cleaned = remove_stopwords(tokens)
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
        cat_tokens = []
        for cat, words in categories.items():
            cat_tokens.extend([token for token in cleaned if token in words])
        
        unique_tokens = list(set(cat_tokens))
        if len(unique_tokens) >= 2:
            edge_counter.update(combinations(unique_tokens, 2))
    
    # ìƒìœ„ ì¡°í•© ì¶”ì¶œ
    top_combos = edge_counter.most_common(9)  # ìƒìœ„ 9ê°œ ì¡°í•©
    
    if top_combos:
        combo_rows = []
        for (item1, item2), count in top_combos:
            # ê° ì•„ì´í…œì˜ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
            cat1 = "ê¸°íƒ€"
            cat2 = "ê¸°íƒ€"
            for cat, words in categories.items():
                if item1 in words:
                    cat1 = cat
                if item2 in words:
                    cat2 = cat
            
            combo_rows.append({
                'ì¡°í•©': f"{item1} + {item2}",
                'ì¹´í…Œê³ ë¦¬': f"{cat1} + {cat2}",
                'í•¨ê»˜ ë“±ì¥': count,
                'ì•„ì´í…œ1': item1,
                'ì•„ì´í…œ2': item2,
                'ì¹´í…Œê³ ë¦¬1': cat1,
                'ì¹´í…Œê³ ë¦¬2': cat2
            })
        
        combo_df = pd.DataFrame(combo_rows)
        
        # ì¡°í•© ì¹´ë“œ í‘œì‹œ
        cols = st.columns(3)
        for i, (_, row) in enumerate(combo_df.iterrows()):
            with cols[i % 3]:
                # ì¹´í…Œê³ ë¦¬ ìƒ‰ìƒ ê²°ì •
                cat1_color = cat_colors.get(row['ì¹´í…Œê³ ë¦¬1'], "#9E9E9E")
                cat2_color = cat_colors.get(row['ì¹´í…Œê³ ë¦¬2'], "#9E9E9E")
                gradient = f"linear-gradient(135deg, {cat1_color}22, {cat2_color}22)"
                
                st.markdown(f"""
                <div style='background: {gradient}; padding:15px; border-radius:10px; box-shadow: 0 2px 5px rgba(0,0,0,0.1);'>
                    <h4 style='text-align:center; margin-top:0;'>{row['ì•„ì´í…œ1']} + {row['ì•„ì´í…œ2']}</h4>
                    <p style='text-align:center;'><span style='color:{cat1_color};'>{row['ì¹´í…Œê³ ë¦¬1']}</span> + <span style='color:{cat2_color};'>{row['ì¹´í…Œê³ ë¦¬2']}</span></p>
                    <p style='text-align:center; font-weight:bold;'>í•¨ê»˜ ë“±ì¥: {row['í•¨ê»˜ ë“±ì¥']}íšŒ</p>
                </div>
                <br>
                """, unsafe_allow_html=True)
    else:
        st.info("ì¶”ì²œ ì¡°í•©ì„ ë¶„ì„í•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")