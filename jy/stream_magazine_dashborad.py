import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re
import glob
from collections import Counter
from wordcloud import WordCloud
import platform

# âœ… í•œê¸€ í°íŠ¸ ê¹¨ì§ ë°©ì§€
plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows
# plt.rcParams['font.family'] = 'AppleGothic'  # Mac
# plt.rcParams['font.family'] = 'NanumGothic'  # Ubuntu
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# ğŸ“Œ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
@st.cache_data
def load_data():
    file_paths = sorted(glob.glob("2025-03-12_merged_fashion_trends.csv"))
    df_list = [pd.read_csv(file, encoding='utf-8-sig') for file in file_paths]
    df = pd.concat(df_list).drop_duplicates(subset=['ì œëª©', 'ê¸°ì‚¬ URL', 'ì—…ë¡œë“œ ë‚ ì§œ'], keep='first').reset_index(drop=True)
    df['ì—…ë¡œë“œ ë‚ ì§œ'] = pd.to_datetime(df['ì—…ë¡œë“œ ë‚ ì§œ'], errors='coerce')
    return df

df = load_data()

# ğŸ“Œ ìš´ì˜ì²´ì œì— ë”°ë¥¸ í•œê¸€ í°íŠ¸ ì„¤ì •
def get_font_path():
    system_name = platform.system()
    if system_name == "Windows":
        return "C:/Windows/Fonts/malgun.ttf"
    elif system_name == "Darwin":
        return "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
    else:
        return "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"

font_path = get_font_path()

# ğŸ“Œ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
stopwords = set(["ìˆë‹¤", "í•˜ëŠ”", "ë°", "ê·¸", "ë”", "ì´", "í•œ", "ìˆ˜", "ê²ƒ", "ìˆìŠµë‹ˆë‹¤", "ë•Œë¬¸ì—", "ì…ë‹ˆë‹¤", "ë‹¤", "ë“±", "ê·¸ë¦¬ê³ ", "í•©ë‹ˆë‹¤", "íŠ¹íˆ", "ì–´ë–¤", "ì—­ì‹œ", "ë‹¤ë¥¸", "ìƒˆë¡œìš´", "ë‹¤ì–‘í•œ", "ìŠ¤íƒ€ì¼ì„", "ë…„ëŒ€",
                 "ë¯¸ì •ìœ¼ë¡œ", "ê·¸ëŠ”", "ì…ê³ ", "ë¸Œëœë“œ", "ê°€ì§€", "ì—¬ê¸°ì—", "ì£¼ëŠ”", "ë£©ì„", "ëŒ€í•œ", "í•¨ê»˜", "ì œí’ˆ", "ë”í•´ì§„", "ì»¬ë ‰ì…˜ì„", "ì»¬ë ‰ì…˜ì€", "ì§€ë‚œ", "ë°”ë¡œ",
                 "ì˜¤ëŠ˜", "íŒ¨ì…˜", "ë§ˆë¦¬", "ëŒ", "ë ˆë¥´", "ì—ë””í„°", "íŠ¸ë Œë“œ", "ëŒ€í•˜", "ì´ë²ˆ", "ë”ìš±", "ê°€ì¥", "ê²ë‹ˆë‹¤", "ê°™ì€", "ê°€", "ì˜", "ì„", "ë¥¼", "ì—", "ì™€", "ìœ¼ë¡œ", "ë¡œ", "ì´ë¼ëŠ”", "ë¼ëŠ”", "ìœ¼ë¡œëŠ”", "ì—ì„œ", "ì´ë¼ê³ ", "ë¼ê³ ", "ì—ê²Œ",
                 "ì´ë¼ë©°", "ë¼ë©°", "ë¼ê³ ë„", "ì´ë¼ê³ ë„", "ìˆëŠ”", "ì€", "ëŠ”", "ê°€", "ê±´", "ë‘", "í†µí•´", "íŠ¹íˆ", "ì–´ë–¤", "ì—­ì‹œ", "ë‹¤ë¥¸", "ìƒˆë¡œìš´", "ë‹¤ì–‘í•œ", "ìŠ¤íƒ€ì¼ì„", "ë…„ëŒ€", "ë¯¸ì •ìœ¼ë¡œ", "ê·¸ëŠ”", "ì…ê³ ", "ë¸Œëœë“œ", "ê°€ì§€", 
                 "ì—¬ê¸°ì—", "ì£¼ëŠ”", "ë£©ì„", "ëŒ€í•œ", "í•¨ê»˜", "ì œí’ˆ", "ë”í•´ì§„", "ì»¬ë ‰ì…˜ì„", "ì»¬ë ‰ì…˜ì€", "ì§€ë‚œ", "ë°”ë¡œ", "ì˜ê°ì„", "ìŠ¤íƒ€ì¼ì˜", "ë‹ë³´ì´ëŠ”", "ì˜", "ê²Œ", "ë“¯í•œ", "ì…ì€", "ì˜·ì„", "ì¤‘", "ëŒ€ì‹ ", "ë³´ì´ëŠ”", "ê·¸ë…€ì˜", "ëª¨ë“ ", "í•˜ì§€ë§Œ", "ì•ŠìŠµë‹ˆë‹¤", "ìœ„ì—", "ì•„ë˜", "ë£¨", "ëª‡", "ë”°ë¼", "ë˜í•œ", "ê±¸", "ì˜¤íˆë ¤", "ì˜¤ëŠ”", "ì–´ëŠ", "í•œê»", "í™œìš©í•œ",
                 "ê²ƒì´ë‹¤", "ë§¤ì¹˜í•´", "ì—¬ëŸ¬", "ì„ ë³´ì˜€ìŠµë‹ˆë‹¤", "ë§Œë“ ", "ì§€ë‹Œ", "ëŒ€í•˜ì—¬", "ì‹œì ˆì˜", "ì„ ë³´ì¸ë‹¤", "ìì‹ ì˜", "ë„˜ì–´", "ì²«", "ì„ ë³´ì˜€ë‹¤", "í™œìš©í•´", "ë”í–ˆë‹¤", "ë§Œë‚˜ë³¼", "ë£©ì—", "ì—°ì¶œí–ˆë‹¤", "ì´ì–´ê°€ê³ ", "ê°€ì§€ê³ ",
                 "ì—†ì´", "ë•Œ", "ì•„ë‹™ë‹ˆë‹¤", "ì—†ëŠ”", "ë§Œí¼", "ë¹„ìŠ·í•œ", "íŒ¨ì…˜ì„", "ë ", "ë‹¤ê°€ì˜¬", "ì§€ê¸ˆ", "ë§ëŠ”", "ì´ë¯¸", "ê²ƒì´", "íŠ¹ìœ ì˜", "í•œì¸µ", "ì „í–ˆë‹¤", "ë”í•´", "ìœ„í•œ", "ë ", "ë²ˆì§¸", "ë°”íƒ•ìœ¼ë¡œ", "í–ˆë‹¤", "ìœ„í•´",
                 "ìˆë„¤ìš”", "ì˜¤ëŠ˜ë„", "ìµœê·¼", "ì´ë ‡ê²Œë‚˜", "ê±°ì˜", "ë³´ì¼", "ê·¸ì˜", "ë§ˆë¦¬ëŒë ˆë¥´", "ì‚´ì§", "ë§Œí•œ", "ì—†ìœ¼ë‹ˆê¹Œìš”", "ìŠ¤í¬ë¡¤ì„", "ë‚´ë ¤ë³´ì„¸ìš”", "ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ë³´ì„¸ìš”", "ì´ëŸ°", "ì•„ë‹ˆë¼", "ìˆì£ ", "ì‹œì ˆ", "ëª¨ë‘", "ì´ì œ", "ë¬´ì—‡ì„", "ë§Œí•œ", "ì¢…ë¥˜ì˜", "ì´ë€", "ì“´", "ë³´ì„¸ìš”", "ì•Šê³ ", "ë§ˆì¹˜", "ê·¸ë…€ëŠ”", "ì—°ì¶œí•œ", "ë³´ì„¸ìš”", "ì•„ë‹Œ", "ì‚´ì§", "ì œëŒ€ë¡œ", "ì•Šì€", "ê²ƒë„", "ê·¸ë…€ê°€", "ë‹¤ì‹œ", "ì™„ì„±í–ˆìŠµë‹ˆë‹¤", "ë“¯", "ì„ ë³´ì¸", "ì˜ˆì •ì´ë‹¤", "ì´ì–´", "ì¤‘ìš”í•œ", "ì¶”ì²œí•©ë‹ˆë‹¤", "ìì£¼", "ë˜", "ë‚ ì„ ë§ì•„", "ì™„ì„±í•˜ëŠ”", "ê·¸ë…€ê°€", "ë„˜ì¹˜ëŠ”", "ê°•ì¡°í–ˆë‹¤", "ì„ ë³´ì´ë©°", "ê°€ì¹˜ë¥¼", "ë“¤ì´", "ê·¸ë“¤ì˜"])

# ğŸ“Œ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ë° ì›Œë“œí´ë¼ìš°ë“œ í•¨ìˆ˜
def show_article_list(filtered_df):
    st.subheader("ğŸ“° ê¸°ì‚¬ ëª©ë¡ ë° ì›Œë“œí´ë¼ìš°ë“œ")
    magazines = filtered_df['ë§¤ê±°ì§„ ëª…'].unique()
    selected_magazine = st.radio("ë§¤ê±°ì§„ ì„ íƒ", list(magazines), horizontal=True)

    filtered_df = filtered_df[filtered_df['ë§¤ê±°ì§„ ëª…'] == selected_magazine]
    col1, col2 = st.columns([1, 1])

    with col1:
        for _, row in filtered_df.iterrows():
            st.markdown(
                f"<div style='padding: 10px; border-radius: 10px; background-color: #f0f0f0; margin-bottom: 10px;'>"
                f"<a href='{row['ê¸°ì‚¬ URL']}' target='_blank' style='text-decoration: none; color: black;'>"
                f"<h6 style='margin: 0;'>{row['ì œëª©']}</h6></a>"
                f"<p style='margin: 5px 0 0; font-size: 12px; color: gray;'>ğŸ—“ {row['ì—…ë¡œë“œ ë‚ ì§œ'].date()}</p></div>",
                unsafe_allow_html=True
            )

    with col2:
        text_content = " ".join(filtered_df['ë³¸ë¬¸'].dropna())
        processed_content = " ".join([word for word in re.findall(r'\b[ê°€-í£]+\b', text_content) if word not in stopwords])
        wordcloud_content = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate(processed_content)

        fig_content, ax_content = plt.subplots(figsize=(5, 5))
        ax_content.imshow(wordcloud_content, interpolation='bilinear')
        ax_content.axis("off")
        st.pyplot(fig_content)

# ğŸ“Œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ í•¨ìˆ˜
def analyze_keyword_trends(filtered_df):
    search_term = st.text_input("ì¶”ì´ë¥¼ í™•ì¸í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "", key="search_term")

    if search_term:
        date_trends = {}
        for _, row in filtered_df.iterrows():
            date = row['ì—…ë¡œë“œ ë‚ ì§œ']
            text = str(row['ë³¸ë¬¸'])
            text = re.sub(r'[^a-zA-Zê°€-í£\s]', '', text.lower())
            words = text.split()
            if date not in date_trends:
                date_trends[date] = Counter()
            date_trends[date].update(words)

        date_trends_df = pd.DataFrame(date_trends).fillna(0).T
        trend_data = pd.Series(0, index=pd.date_range(start=filtered_df["ì—…ë¡œë“œ ë‚ ì§œ"].min(), end=filtered_df["ì—…ë¡œë“œ ë‚ ì§œ"].max()))
        if not date_trends_df.empty and search_term in date_trends_df.columns:
            trend_data.update(date_trends_df[search_term])

        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(trend_data.index, trend_data.values, marker='o', linestyle='-', color='b')
        ax.set_xlabel("ë‚ ì§œ")
        ax.set_ylabel("í‚¤ì›Œë“œ ë¹ˆë„")
        ax.set_title(f"'{search_term}' í‚¤ì›Œë“œì˜ ë‚ ì§œë³„ ë³€í™” ì¶”ì´")
        ax.tick_params(axis='x', rotation=45)
        st.pyplot(fig)

# ğŸ“Œ ì»¬ëŸ¬ í‚¤ì›Œë“œ ë¶„ì„ í•¨ìˆ˜
def analyze_color_trends(filtered_df):
    color_list = ["ë¸”ë™", "í™”ì´íŠ¸", "ë² ì´ì§€", "ë¸Œë¼ìš´", "ê·¸ë ˆì´", "ë¸”ë£¨", "ìŠ¤ì¹´ì´ë¸”ë£¨", "ë„¤ì´ë¹„",
                  "ì˜ë¡œìš°", "í•‘í¬", "ë ˆë“œ", "ì¹´í‚¤", "ë¼ë²¤ë”", "ê·¸ë¦°", "í¼í”Œ", "ë¯¼íŠ¸", "ì˜¤ë Œì§€"]

    color_counts = {color: filtered_df["ë³¸ë¬¸"].str.contains(color, case=False, na=False).sum() for color in color_list}
    sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)
    sorted_colors_dict = dict(sorted_colors)

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.bar(sorted_colors_dict.keys(), sorted_colors_dict.values(), color="black")
    ax.set_ylabel("ë¹ˆë„ìˆ˜")
    ax.set_xlabel("ì»¬ëŸ¬")
    ax.set_title("ì»¬ëŸ¬ë³„ ë“±ì¥ ë¹ˆë„ìˆ˜ (ë‚´ë¦¼ì°¨ìˆœ)")
    plt.xticks(rotation=45)
    st.pyplot(fig)

# ğŸ“Œ ì‚¬ì´ë“œë°” - ê¸°ê°„ ì„ íƒ í•„í„°
st.sidebar.header("ğŸ“… ê¸°ê°„ í•„í„°")
start_date = st.sidebar.date_input("ì‹œì‘ ë‚ ì§œ", df["ì—…ë¡œë“œ ë‚ ì§œ"].min())
end_date = st.sidebar.date_input("ì¢…ë£Œ ë‚ ì§œ", df["ì—…ë¡œë“œ ë‚ ì§œ"].max())

# âœ… ì„ íƒí•œ ê¸°ê°„ ë‚´ ë°ì´í„° í•„í„°ë§
filtered_df = df[(df["ì—…ë¡œë“œ ë‚ ì§œ"] >= pd.to_datetime(start_date)) & (df["ì—…ë¡œë“œ ë‚ ì§œ"] <= pd.to_datetime(end_date))]

# ğŸ“Œ Streamlit UI - íƒ­ ë©”ë‰´ êµ¬ì„±
st.title("ğŸ“Š íŒ¨ì…˜ íŠ¸ë Œë“œ ë°ì´í„° ë¶„ì„")

tab1, tab2, tab3 = st.tabs(["ê¸°ì‚¬ ë° ì›Œë“œí´ë¼ìš°ë“œ", "í‚¤ì›Œë“œ íŠ¸ë Œë“œ", "ì»¬ëŸ¬ íŠ¸ë Œë“œ"])

with tab1:
    show_article_list(filtered_df)

with tab2:
    analyze_keyword_trends(filtered_df)

with tab3:
    analyze_color_trends(filtered_df)
